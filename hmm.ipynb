{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "- Decapitalise everything. Either:\n",
    "    - lowercase every token after a '.' token or\n",
    "    - lowercase everything\n",
    "    - I go with 2nd option because there are other punctuation marks (some of which are quotes) and I don't want to do SBD\n",
    "    - I need to distinguish between UNKNOWNs and NAMEs which have tag Propernoun\n",
    "\n",
    "The plan:\n",
    "\n",
    "- Write script to list out all tokens with less than 0.0001N counts\n",
    "- Write script to replace all tokens with less than 0.0001N counts with <UNKNOWN>\n",
    "- Separate the sentences\n",
    "- Get the counts (according to slide 14/39). Sum over each sentence\n",
    "    - Transition count of each state pair. Emission count of each state-token pair.\n",
    "- Estimate original values using slide 14/39\n",
    "** Separate the sentences into 90-10 split for training and evaluation\n",
    "- Online EM learn\n",
    "    - Stepwise EM or whatever the fuck it's called\n",
    "    - μ=(1−ηk​)μ+ηk​μ′\n",
    "    - ηk is simply a step statistic: 1/(k+1)^a for iteration k\n",
    "    - I guess we set alpha to 0.7\n",
    "** Viterbi EM may not even be necessary? But we can implement it afterwards if it takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CoNLL-U file\n",
    "file_path = 'ptb-train.conllu'\n",
    "\n",
    "# Initialize list to store rows, sentence counter, and token counter\n",
    "data = []\n",
    "sentence_id = 0\n",
    "token_id = 0\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if not line:  # Empty line indicates new sentence\n",
    "            sentence_id += 1\n",
    "            token_id = 0  # Reset token counter for the new sentence\n",
    "        else:\n",
    "            token_id += 1  # Increment token id for each token in a sentence\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) == 10:\n",
    "                data.append([sentence_id] + parts)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['sentence_id', 'id', 'form', 'blank', 'upos', 'xpos', 'blank', 'head', 'deprel', 'deps', 'blank'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'ptb-train.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('ptb-train.csv')  \n",
    "column_name = 'form'\n",
    "forms = df[column_name]\n",
    "\n",
    "# Calculate frequency distribution of words\n",
    "frequency = forms.value_counts()\n",
    "\n",
    "# Plot the frequency distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "frequency.plot(kind='line', logy=True)  # log scale for better visibility\n",
    "plt.title('Frequency Distribution of Words')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Output the frequency distribution\n",
    "print(frequency)\n",
    "\n",
    "# Check the result or save the updated DataFrame\n",
    "print(df.head())  # Prints the first few rows of the updated DataFrame\n",
    "# df.to_csv('updated_file.csv', index=False)  # Uncomment to save the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('ptb-train.csv', keep_default_na=False, na_values=[''])\n",
    "column_name = 'form'\n",
    "upos_column = 'upos'\n",
    "\n",
    "# Lowercase everything\n",
    "df[column_name] = df[column_name].str.lower()\n",
    "\n",
    "# Calculate frequency distribution of words\n",
    "counts = df[column_name].value_counts()\n",
    "\n",
    "# Apply 'UNKNOWN' or 'NAME' based on frequency and whether the word is a proper noun\n",
    "threshold = 4\n",
    "df[column_name] = df.apply(\n",
    "    lambda row: 'NUM' if row[upos_column] == 'NUM' else\n",
    "                ('NAME' if row[upos_column] == 'PROPN' else \n",
    "                ('UNKNOWN' if counts.get(row[column_name], 0) < threshold else row[column_name])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "output = f'ptb-train-{threshold}-all-lower.csv'\n",
    "# Save to new csv\n",
    "df.to_csv(output, index=False)\n",
    "print(f\"Updated DataFrame (all lowercase) saved to {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_sentences(df: pd.DataFrame, id_col = 'id', forms_col = 'form', pos_tags_col = 'upos'):\n",
    "    output = []\n",
    "    current_sentence = []\n",
    "    current_pos = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[id_col] == 1 and current_sentence:\n",
    "            output.append((current_sentence, current_pos))\n",
    "            current_sentence, current_pos = [row[forms_col]], [row[pos_tags_col]]\n",
    "        else:\n",
    "            current_sentence.append(row[forms_col])\n",
    "            current_pos.append(row[pos_tags_col])\n",
    "\n",
    "    # Append the last sentence if it's not empty\n",
    "    if current_sentence:\n",
    "        output.append((current_sentence, current_pos))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def write_sentences_to_file(sentences, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for sentence, pos_tags in sentences:\n",
    "            # Writing words and POS tags on separate lines\n",
    "            file.write('Words: ' + ' '.join(sentence) + '\\n')\n",
    "            file.write('Tags: ' + ' '.join(pos_tags) + '\\n')\n",
    "            file.write('\\n')  # Adding a blank line between sentences for clarity\n",
    "\n",
    "df = pd.read_csv('ptb-train-4-all-lower.csv')\n",
    "processed = process_sentences(df)\n",
    "write_sentences_to_file(processed, 'output_sentences.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ptb-train-4-all-lower.csv')\n",
    "processed_sentences, processed_tags = [x[0] for x in processed], [x[1] for x in processed]\n",
    "\n",
    "unique_words = sorted(df['form'].unique())\n",
    "unique_words_dict = {w: i for (i, w) in enumerate(unique_words)}\n",
    "unique_upos = sorted(df['upos'].unique())\n",
    "unique_upos_dict = {t: i for (i, t) in enumerate(unique_upos)}\n",
    "\n",
    "M = len(unique_words)\n",
    "N = len(unique_upos)\n",
    "\n",
    "print(unique_words)\n",
    "print(unique_upos)\n",
    "\n",
    "\n",
    "def make_transition_matrix(epsilon=1):\n",
    "\n",
    "    transition_matrix = np.zeros((N, N))\n",
    "    transition_counts = {key: {k: 0 for k in unique_upos_dict.keys()} for key in unique_upos_dict.keys()}\n",
    "\n",
    "    for sequence in processed_tags:\n",
    "        for i in range(len(sequence) - 1):\n",
    "            current_tag = sequence[i]\n",
    "            next_tag = sequence[i + 1]\n",
    "            if current_tag in unique_upos_dict and next_tag in unique_upos_dict:\n",
    "                transition_counts[current_tag][next_tag] += 1\n",
    "\n",
    "    for a in unique_upos_dict:\n",
    "        total_transitions_from_a = sum(transition_counts[a].values()) + epsilon * N\n",
    "\n",
    "        for b in unique_upos_dict:\n",
    "            transition_matrix[unique_upos_dict[a], unique_upos_dict[b]] = (transition_counts[a][b] + epsilon) / total_transitions_from_a\n",
    "\n",
    "    print(transition_matrix)\n",
    "    return transition_matrix\n",
    "\n",
    "def make_emission_matrix(epsilon = 1):\n",
    "\n",
    "    emission_matrix = np.zeros((N, M))\n",
    "    emission_counts = {key: {tag: 0 for tag in unique_words_dict.keys()} for key in unique_upos_dict.keys()}\n",
    "\n",
    "    for j in range(len(processed_tags)):\n",
    "        sentence = processed_sentences[j]\n",
    "        sequence = processed_tags[j]\n",
    "        for i in range(len(sequence)):\n",
    "            current_tag = sequence[i]\n",
    "            current_emission = sentence[i]\n",
    "            if current_tag in unique_upos_dict and current_emission in unique_words_dict:\n",
    "                emission_counts[current_tag][current_emission] += 1\n",
    "\n",
    "    for a in unique_upos_dict:\n",
    "        total_emissions_from_a = sum(emission_counts[a].values()) + epsilon * M\n",
    "        for b in unique_words_dict:\n",
    "            emission_matrix[unique_upos_dict[a], unique_words_dict[b]] = (emission_counts[a][b] + epsilon) / total_emissions_from_a\n",
    "\n",
    "    print(emission_matrix)\n",
    "    return emission_matrix\n",
    "\n",
    "def make_initial(epsilon=0):\n",
    "    initial_probabilities = np.zeros(len(unique_upos_dict))\n",
    "    initial_counts = {tag: 0 for tag in unique_upos_dict.keys()}\n",
    "    total_sentences = len(processed_tags)\n",
    "\n",
    "    for tags in processed_tags:\n",
    "        if tags:  # Check it exists\n",
    "            initial_tag = tags[0]\n",
    "            if initial_tag in initial_counts:\n",
    "                initial_counts[initial_tag] += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    for tag, index in unique_upos_dict.items():\n",
    "        initial_probabilities[index] = (initial_counts[tag] + epsilon) / total_sentences\n",
    "\n",
    "    return initial_probabilities\n",
    "\n",
    "t_matrix, e_matrix, initial = make_transition_matrix(), make_emission_matrix(), make_initial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_matrix[unique_upos_dict['NOUN']][unique_upos_dict['ADV']])\n",
    "# NOUN -> ADV 0.02721837801995658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 17)\n",
      "(17, 9962)\n"
     ]
    }
   ],
   "source": [
    "print(t_matrix.shape)\n",
    "print(e_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTDATED IMPLEMENTATIONS, NOT IN LOG SPACE (and not vectorised)\n",
    "\n",
    "# # No end probabilities, so I just don't calculate them\n",
    "# def forward(tags, word_sequence, initial, words_dict, transition, emission):\n",
    "#     # node values stored during forward algorithm\n",
    "#     node_values_fwd = np.zeros((len(tags), len(word_sequence)))\n",
    "\n",
    "#     # i is index of observed sequence, k is across hidden states\n",
    "#     for i, word in enumerate(word_sequence):\n",
    "#         for j in range(len(tags)):\n",
    "#             # if first sequence value\n",
    "#             if (i == 0):\n",
    "#                 node_values_fwd[j, i] = initial[j] * emission[j, words_dict[word]]\n",
    "#             else:\n",
    "#                 values = [node_values_fwd[k, i - 1] * emission[j, words_dict[word]] \n",
    "#                           * transition[k, j] for k in range(len(tags))]\n",
    "#                 node_values_fwd[j, i] = sum(values)\n",
    "\n",
    "#     forward_val = sum(node_values_fwd[:, -1])\n",
    "#     return node_values_fwd, forward_val\n",
    "\n",
    "\n",
    "# # No end probabilities, so I assume the prob of landing on any hidden state last is 1\n",
    "# def backward(tags, word_sequence, initial, words_dict, transition, emission):\n",
    "#     # node values stored during forward algorithm\n",
    "#     backward_vals = np.zeros((len(tags), len(word_sequence)))\n",
    "\n",
    "#     #for i, sequence_val in enumerate(test_sequence):\n",
    "#     for i in range(1,len(word_sequence)+1):\n",
    "#         for j in range(len(tags)):\n",
    "#             # if first sequence value then do this\n",
    "#             if (-i == -1):\n",
    "#                 backward_vals[j, -i] = 1\n",
    "#             else:\n",
    "#                 values = [backward_vals[k, -i+1] * emission[k, words_dict[word_sequence[-i+1]]] * transition[j, k] for k in range(len(tags))]\n",
    "#                 backward_vals[j, -i] = sum(values)\n",
    "\n",
    "#     start_state = [backward_vals[m,0] * emission[m, words_dict[word_sequence[0]]] for m in range(len(tags))]\n",
    "#     start_state = np.multiply(start_state, initial)\n",
    "#     backward_val = sum(start_state)\n",
    "#     return backward_vals, backward_val\n",
    "\n",
    "\n",
    "# #function to find si probabilities\n",
    "# def si_probs(states, word_sequence, forward, backward, forward_val, words_dict, transition, emission):\n",
    "\n",
    "#     si_probabilities = np.zeros((len(states), len(word_sequence)-1, len(states)))\n",
    "\n",
    "#     # i is observed state index\n",
    "#     # We are going from hidden state indexes j to k, at times i to i+1\n",
    "#     for i in range(len(word_sequence)-1):\n",
    "#         for j in range(len(states)):\n",
    "#             for k in range(len(states)):\n",
    "#                 si_probabilities[j,i,k] = ( forward[j,i] * backward[k,i+1] * transition[j,k] * emission[k,words_dict[word_sequence[i+1]]] ) / forward_val\n",
    "#     return si_probabilities\n",
    "\n",
    "# #function to find gamma probabilities\n",
    "# # forward_val \n",
    "# def gamma_probs(tags, test_sequence, forward, backward, forward_val):\n",
    "\n",
    "#     gamma_probabilities = np.zeros((len(tags), len(test_sequence)))\n",
    "\n",
    "#     for i in range(len(test_sequence)):\n",
    "#         for j in range(len(tags)):\n",
    "#             gamma_probabilities[j, i] = (forward[j, i] * backward[j, i]) / forward_val\n",
    "\n",
    "#     return gamma_probabilities\n",
    "\n",
    "\n",
    "# def baum(target_sequence, transition, emission, initial, tags, tags_dict, words, words_dict):\n",
    "\n",
    "#     fwd_probs, fwd_val = forward(tags, target_sequence, initial, words_dict, transition, emission)\n",
    "#     bwd_probs, bwd_val = backward(tags, target_sequence, initial, words_dict, transition, emission)\n",
    "#     si_probabilities = si_probs(tags, target_sequence, fwd_probs, bwd_probs, fwd_val, words_dict, transition, emission)\n",
    "#     gamma_probabilities = gamma_probs(tags, target_sequence, fwd_probs, bwd_probs, fwd_val)\n",
    "#     word_indices = np.array([words_dict[word] for word in target_sequence])\n",
    "\n",
    "#     #caclculating 'a' and 'b' matrices\n",
    "#     a = np.zeros((len(tags), len(tags)))\n",
    "#     b = np.zeros((len(tags), len(words_dict)))\n",
    "\n",
    "#     #'a' matrix\n",
    "#     for j in range(len(tags)):\n",
    "#         for i in range(len(tags)):\n",
    "#             for t in range(len(target_sequence)-1):\n",
    "#                 a[j,i] = a[j,i] + si_probabilities[j,t,i]\n",
    "\n",
    "#             denom_a = [si_probabilities[j, t_x, i_x] for t_x in range(len(target_sequence) - 1) for i_x in range(len(tags))]\n",
    "#             denom_a = sum(denom_a)\n",
    "\n",
    "#             if (denom_a == 0):\n",
    "#                 a[j,i] = 0\n",
    "#             else:\n",
    "#                 a[j,i] = a[j,i]/denom_a\n",
    "\n",
    "\n",
    "#     #'b' matrix\n",
    "#     for j in range(len(tags)):\n",
    "#         for i in range(len(words)): \n",
    "#             indices = [idx for idx, val in enumerate(target_sequence) if val == words[i]]\n",
    "#             numerator_b = sum( gamma_probabilities[j,indices] )\n",
    "#             denomenator_b = sum( gamma_probabilities[j,:] )\n",
    "\n",
    "#             if (denomenator_b == 0):\n",
    "#                 b[j,i] = 0\n",
    "#             else:\n",
    "#                 b[j, i] = numerator_b / denomenator_b\n",
    "\n",
    "\n",
    "#     print('\\nMatrix a:\\n')\n",
    "#     print(np.matrix(a.round(decimals=4)))\n",
    "#     print('\\nMatrix b:\\n')\n",
    "#     print(np.matrix(b.round(decimals=4)))\n",
    "\n",
    "#     return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "import random\n",
    "\n",
    "import cProfile\n",
    "\n",
    "# Transition and Emission are already log\n",
    "# def forward_log_vec(num_tags, num_words, log_initial, log_transition, log_emission_sentence):\n",
    "#     # num_words = len(word_indices)\n",
    "#     log_probs = np.full((num_tags, num_words), -np.inf)  # log(0) = -inf\n",
    "#     scaling_factors = np.zeros(num_words)\n",
    "    \n",
    "#     log_probs[:, 0] = log_initial + log_emission_sentence[:, 0]\n",
    "#     # NORMALISE\n",
    "#     # factor0 = logsumexp(log_probs[:, 0])\n",
    "#     # log_probs[:, 0] -= factor0\n",
    "#     # scaling_factors[0] = factor0\n",
    "\n",
    "#     for t in range(1, num_words):\n",
    "#         log_probs[:, t] = logsumexp(log_probs[:, t-1].reshape(-1, 1) + log_transition, axis=0) + log_emission_sentence[:, t]\n",
    "#         print(f\"{log_probs[:,t]=}\")\n",
    "#         # NORMALISE\n",
    "#         # factor = logsumexp(log_probs[:, t])\n",
    "#         # log_probs[:, t] -= factor\n",
    "#         # scaling_factors[t] = factor\n",
    "#         # print(f\"{np.exp(factor)=}\")\n",
    "\n",
    "\n",
    "#     forward_val = logsumexp(log_probs[:, -1])\n",
    "#     # forward_val = np.sum(scaling_factors)\n",
    "#     print(f\"{np.exp(forward_val)=}\")\n",
    "\n",
    "#     # print(f\"{log_probs=}\")\n",
    "#     return log_probs, forward_val\n",
    "\n",
    "def forward_log_vec(num_tags, num_words, log_initial, log_transition, log_emission_sentence):\n",
    "    forward_vals = np.full((num_tags, num_words), -np.inf)\n",
    "    scaling_factors = np.zeros(num_words)\n",
    "\n",
    "    forward_vals[:, 0] = log_initial + log_emission_sentence[:, 0]\n",
    "    # NORMALISE\n",
    "    factor0 = logsumexp(forward_vals[:, 0])\n",
    "    forward_vals[:, 0] -= factor0\n",
    "    scaling_factors[0] = factor0\n",
    "    \n",
    "    for t in range(1, num_words):\n",
    "        # Compute log probabilities\n",
    "        forward_vals[:, t] = logsumexp(forward_vals[:, t-1][:, np.newaxis] + log_transition, axis=0) + log_emission_sentence[:, t]\n",
    "        # NORMALISE\n",
    "        factor = logsumexp(forward_vals[:, t])\n",
    "        forward_vals[:, t] -= factor\n",
    "        scaling_factors[t] = factor\n",
    "\n",
    "        # print(f\"{np.sum(np.exp(forward_vals[:, t]))=}\")\n",
    "    # print(f\"{forward_vals}\")\n",
    "    \n",
    "    return forward_vals, -np.sum(scaling_factors)\n",
    "\n",
    "# Implementation using scaling factors from forward algorithm\n",
    "# def backward_log_vec(num_tags, num_words, log_transition, log_emission_sentence, scaling_factors):\n",
    "#     # num_words = len(word_indices)\n",
    "#     backward_vals = np.zeros(num_tags, num_words)\n",
    "    \n",
    "#     # Last column, deduct scaling factor\n",
    "#     backward_vals[:, -1] -= scaling_factors[-1]\n",
    "    \n",
    "#     for t in range(num_words-2, -1, -1):\n",
    "#         backward_vals[:, t] = logsumexp(backward_vals[:, t + 1][:, np.newaxis] + log_transition, axis=1) + log_emission_sentence[:, t + 1]\n",
    "#         # NORMALISE\n",
    "#         backward_vals[:, t] -= scaling_factors[:, t]\n",
    "#     # print(scaling_factors)\n",
    "\n",
    "#     return backward_vals\n",
    "\n",
    "def backward_log_vec(num_tags, num_words, log_transition, log_emission_sentence):\n",
    "    # num_words = len(word_indices)\n",
    "    backward_vals = np.full((num_tags, num_words), -np.inf)\n",
    "    # Last column, deduct scaling factor\n",
    "    backward_vals[:, -1] = 0\n",
    "    backward_vals[:, -1] -= logsumexp(backward_vals[:, -1])\n",
    "    for t in range(num_words-2, -1, -1):\n",
    "        backward_vals[:, t] = logsumexp(backward_vals[:, t + 1][:, np.newaxis] + log_transition, axis=1) + log_emission_sentence[:, t + 1]\n",
    "        # NORMALISE\n",
    "        backward_vals[:, t] -= logsumexp(backward_vals[:, t])\n",
    "    # print(f\"{backward_vals=}\")\n",
    "\n",
    "    return backward_vals\n",
    "\n",
    "\n",
    "def log_si_probs_vec(log_forward, log_backward, log_forward_val, log_transition, log_emission_sentences):\n",
    "\n",
    "    return (log_forward[:, :-1, np.newaxis] +\n",
    "        log_backward[:, 1:].T[np.newaxis, :] +\n",
    "        log_transition[:, np.newaxis, :] + \n",
    "        log_emission_sentences[:, 1:].T[np.newaxis, :]\n",
    "        - log_forward_val\n",
    "    )\n",
    "\n",
    "    # if np.any(np.isnan(f)):\n",
    "    #     print(\"log_si_probs NAAN detected\")\n",
    "    #     print(\"Forward:\", log_forward)\n",
    "    #     print(\"Forward shape:\", log_forward.shape)\n",
    "    #     print(\"Backward:\", log_backward)\n",
    "    #     print(\"Transition:\", log_transition)\n",
    "    #     print(\"Emission Sentences:\", log_emission_sentences)\n",
    "    #     print(\"log_forward_val:\", log_forward_val)\n",
    "\n",
    "    # if np.any(np.isneginf(f)):\n",
    "    #     print(\"log_si_probs -inf detected\")\n",
    "    #     print(\"Forward:\", log_forward)\n",
    "    #     print(\"Backward:\", log_backward)\n",
    "    #     print(\"Transition:\", log_transition)\n",
    "    #     print(\"Emission Sentences:\", log_emission_sentences)\n",
    "    #     print(\"log_forward_val:\", log_forward_val)\n",
    "\n",
    "    # print(f\"log_si_probs = {f}\")\n",
    "    \n",
    "    # return f\n",
    "\n",
    "# def log_si_probs_vec(num_tags, word_indices, log_forward, log_backward, log_forward_val, transition, log_emission_sentences):\n",
    "#     assert np.all(log_forward < 0)\n",
    "#     assert np.all(log_backward < 0)\n",
    "#     assert np.all(transition < 0)\n",
    "#     assert np.all(log_emission_sentences < 0)\n",
    "#     print(f\"{log_forward_val=}\")\n",
    "    \n",
    "    \n",
    "#     si_probabilities = np.full((num_tags, len(word_indices)-1, num_tags), -np.inf)\n",
    "\n",
    "#     for i in range(len(word_indices)-1):\n",
    "#         for j in range(num_tags):\n",
    "#             for k in range(num_tags):\n",
    "#                 si_probabilities[j, i, k] = (\n",
    "#                     log_forward[j, i] +\n",
    "#                     log_backward[k, i+1] +\n",
    "#                     transition[j, k] +\n",
    "#                     log_emission_sentences[k, i+1] -\n",
    "#                     log_forward_val\n",
    "#                 )\n",
    "#     print(f\"{si_probabilities=}\")\n",
    "#     return si_probabilities\n",
    "\n",
    "\n",
    "\n",
    "# def baum_log(target_sentence, log_transition, log_emission, log_initial, tags, words_dict):\n",
    "\n",
    "#     word_indices = np.array([words_dict[word] for word in target_sentence])\n",
    "#     num_tags = len(tags)\n",
    "#     num_target_words = len(word_indices)\n",
    "#     num_words = len(words_dict)\n",
    "#     # print(f'{log_emission.shape=}')\n",
    "#     # print(f'{type(log_emission)=}')\n",
    "#     # print(word_indices)\n",
    "#     # print(f'{log_emission[:, np.array(word_indices)]=}')\n",
    "#     log_emission_sentence = log_emission[:, word_indices]\n",
    "#     # print(f'{log_emission_sentence[:, 0].shape=}')\n",
    "#     # print(f'{log_initial.shape=}')\n",
    "\n",
    "#     # print(target_sentence)\n",
    "#     log_fwd_probs, log_fwd_val = forward_log_vec(num_tags, num_target_words, log_initial, log_transition, log_emission_sentence)\n",
    "#     log_bwd_probs = backward_log_vec(num_tags, num_target_words, log_transition, log_emission_sentence)\n",
    "\n",
    "#     # log_si_probabilities = log_si_probs_vec(num_tags, word_indices, log_fwd_probs, log_bwd_probs, log_fwd_val, log_transition, log_emission_sentence)\n",
    "#     log_si_probabilities = log_si_probs_vec(log_fwd_probs, log_bwd_probs, log_fwd_val, log_transition, log_emission_sentence)\n",
    "\n",
    "#     # No more function for gamma, too simple\n",
    "#     log_gamma_probabilities = log_fwd_probs + log_bwd_probs - log_fwd_val\n",
    "\n",
    "#     # a matrix\n",
    "#     # print(f'{log_si_probabilities.reshape(num_tags, -1).shape=}')\n",
    "#     # print(f'{log_si_probabilities.shape=}')\n",
    "#     a1 = logsumexp(log_si_probabilities, axis=1)\n",
    "#     a2 = logsumexp(log_si_probabilities, axis=(1, 2))[:, np.newaxis]\n",
    "#     log_a = a1 - a2\n",
    "#     if np.any(np.isnan(log_a)):\n",
    "#         print(\"log_a NAAN detected\")\n",
    "#         print(\"Expected transitions from state i to j:\", a1)\n",
    "#         print(\"Expected total transitions from state i:\", a2)\n",
    "#         # print(\"FORWARD:\", copy_fwd)\n",
    "#         # print(\"FORWARD SHAPE:\", copy_fwd.shape)\n",
    "#         # print(\"BACKWARD:\", copy_bwd)\n",
    "#         print(\"TARGET SENTENCE\", target_sentence)\n",
    "#         print(\"SI:\", log_si_probabilities)\n",
    "#         print(\"Old Transition Matrix:\", log_transition)\n",
    "\n",
    "#     # b matrix\n",
    "#     b_denominator_logs = logsumexp(log_gamma_probabilities, axis=1, keepdims=True)  # Shape: (num_states, 1)\n",
    "#     # Pray we don't need to handle cases where denominator is -inf\n",
    "#     assert np.all(~np.isneginf(b_denominator_logs)), \"Error: denominator contains -inf values.\"\n",
    "#     unique_word_indices, inverse_indices = np.unique(word_indices, return_inverse=True)\n",
    "#     num_unique_words = len(unique_word_indices)\n",
    "#     b_numerator_logs = np.full((num_tags, num_unique_words), -np.inf)\n",
    "#     # np.add.at(numerator_logs, (slice(None), inverse_indices), log_gamma_probabilities)\n",
    "    # for idx in range(num_unique_words):\n",
    "    #     mask = (inverse_indices == idx)\n",
    "    #     b_numerator_logs[:, idx] = logsumexp(log_gamma_probabilities[:, mask], axis=1)\n",
    "\n",
    "    # log_b = np.full((num_tags, num_words), -np.inf)\n",
    "    # log_b[:, unique_word_indices] = b_numerator_logs - b_denominator_logs\n",
    "\n",
    "    # cem[:, unique_ind] = logsumexp([cem[:, unique_ind], current_b_num_logs], axis=)\n",
    "    \n",
    "\n",
    "    # print(f\"{log_a=}\")\n",
    "    # print(f\"{log_b=}\")\n",
    "    # print(f\"{log_b[:, unique_word_indices]=}\")\n",
    "    \n",
    "    # return log_a, log_b\n",
    "\n",
    "# def baum_welch_stepwise_loggers(sentences, initial_transition, initial_emission, initial_prob, tags, words_dict, alpha=0.7, max_iterations=1000, log_convergence_threshold=np.log(0.01), batch_size=100):\n",
    "#     log_transition = np.log(initial_transition)\n",
    "#     log_emission = np.log(initial_emission)\n",
    "#     log_initial = np.log(initial_prob)\n",
    "\n",
    "#     assert np.all(~np.isneginf(log_transition)), \"Error: transition contains -inf values.\"\n",
    "#     assert np.all(~np.isneginf(log_emission)), \"Error: emission contains -inf values.\"\n",
    "#     assert np.all(~np.isneginf(log_initial)), \"Error: initial contains -inf values.\"\n",
    "\n",
    "#     iteration = 0\n",
    "#     converged = False\n",
    "#     num_sentences = len(sentences)\n",
    "\n",
    "#     while iteration < max_iterations and not converged:\n",
    "#         np.random.shuffle(sentences)\n",
    "#         print(f'Iteration: {iteration}')\n",
    "\n",
    "#         for i in range(0, num_sentences, batch_size):\n",
    "#             batch = sentences[i:i + batch_size]\n",
    "#             batch_log_a = []\n",
    "#             batch_log_b = []\n",
    "\n",
    "#             for sentence in batch:\n",
    "#                 log_a, log_b = baum_log(sentence, log_transition, log_emission, log_initial, tags, words_dict)\n",
    "#                 batch_log_a.append(log_a)\n",
    "#                 batch_log_b.append(log_b)\n",
    "\n",
    "#             # Aggregate updates for the batch\n",
    "#             log_af = logsumexp(batch_log_a, axis=0) - np.log(len(batch_log_a))\n",
    "#             log_bf = logsumexp(batch_log_b, axis=0) - np.log(len(batch_log_b))\n",
    "\n",
    "#             # print(f\"{len(batch_log_a)=}\")\n",
    "#             # print(f\"{len(batch_log_b)=}\")\n",
    "\n",
    "#             # iteration + 2 because (1 - learning_rate) is 0 when iteration is 0\n",
    "#             learning_rate = 1 / ((iteration + 2) ** alpha)\n",
    "#             lr0, lr1 = np.log(learning_rate), np.log(1 - learning_rate)\n",
    "\n",
    "#             # Immediate EM update per batch using weighted average in log space\n",
    "#             log_transition = logsumexp([log_transition + lr1, log_af + lr0], axis=0)\n",
    "#             log_emission = logsumexp([log_emission + lr1, log_bf + lr0], axis=0)\n",
    "\n",
    "#         prev_transition = np.copy(log_transition) if iteration == 0 else prev_transition\n",
    "#         prev_emission = np.copy(log_emission) if iteration == 0 else prev_emission\n",
    "\n",
    "#         # Check convergence\n",
    "#         if np.max(np.abs(log_transition - prev_transition)) < log_convergence_threshold and \\\n",
    "#            np.max(np.abs(log_emission - prev_emission)) < log_convergence_threshold:\n",
    "#             converged = True\n",
    "\n",
    "#         # DEBUGGING PURPOSES: STOP AT 1 ITERATION\n",
    "#         # if iteration == 1:\n",
    "#         #     converged = True\n",
    "\n",
    "#         prev_transition = np.copy(log_transition)\n",
    "#         prev_emission = np.copy(log_emission)\n",
    "#         # if iteration % 10 == 0:\n",
    "#         if iteration in range(10):\n",
    "#             print(f\"{prev_emission=}\")\n",
    "#             print(f\"{prev_transition=}\")\n",
    "#         iteration += 1\n",
    "\n",
    "#     # Convert back to probabilities if needed for interpretation\n",
    "#     transition = np.exp(log_transition)\n",
    "#     emission = np.exp(log_emission)\n",
    "\n",
    "#     return transition, emission\n",
    "\n",
    "def baum_log(target_sentence, log_transition, log_emission, log_initial, tags, words_dict):\n",
    "\n",
    "    word_indices = np.array([words_dict[word] for word in target_sentence])\n",
    "    num_tags = len(tags)\n",
    "    num_target_words = len(word_indices)\n",
    "    num_words = len(words_dict)\n",
    "    # print(f'{log_emission.shape=}')\n",
    "    # print(f'{type(log_emission)=}')\n",
    "    # print(word_indices)\n",
    "    # print(f'{log_emission[:, np.array(word_indices)]=}')\n",
    "    log_emission_sentence = log_emission[:, word_indices]\n",
    "    # print(f'{log_emission_sentence[:, 0].shape=}')\n",
    "    # print(f'{log_initial.shape=}')\n",
    "\n",
    "    # print(target_sentence)\n",
    "    log_fwd_probs, log_fwd_val = forward_log_vec(num_tags, num_target_words, log_initial, log_transition, log_emission_sentence)\n",
    "    log_bwd_probs = backward_log_vec(num_tags, num_target_words, log_transition, log_emission_sentence)\n",
    "    \n",
    "    # log_si_probabilities = log_si_probs_vec(num_tags, word_indices, log_fwd_probs, log_bwd_probs, log_fwd_val, log_transition, log_emission_sentence)\n",
    "    log_si_probabilities = log_si_probs_vec(log_fwd_probs, log_bwd_probs, log_fwd_val, log_transition, log_emission_sentence)\n",
    "\n",
    "    # No more function for gamma, too simple\n",
    "    log_gamma_probabilities = log_fwd_probs + log_bwd_probs - log_fwd_val\n",
    "\n",
    "    a1 = logsumexp(log_si_probabilities, axis=1)\n",
    "    a2 = logsumexp(log_si_probabilities, axis=(1, 2))[:, np.newaxis]\n",
    "    b2 = logsumexp(log_gamma_probabilities, axis=1, keepdims=True)\n",
    "    # assert np.all(~np.isneginf(b2)), \"Error: denominator contains -inf values.\"\n",
    "\n",
    "    unique_word_indices, inverse_indices = np.unique(word_indices, return_inverse=True)\n",
    "    num_unique_words = len(unique_word_indices)\n",
    "    btemp = np.full((num_tags, num_unique_words), -np.inf)\n",
    "    # np.add.at(numerator_logs, (slice(None), inverse_indices), log_gamma_probabilities)\n",
    "    for idx in range(num_unique_words):\n",
    "        mask = (inverse_indices == idx)\n",
    "        btemp[:, idx] = logsumexp(log_gamma_probabilities[:, mask], axis=1)\n",
    "    b1 = np.full((num_tags, num_words), -np.inf)\n",
    "    b1[:, unique_word_indices] = btemp\n",
    "\n",
    "    return a1, a2, b1, b2\n",
    "\n",
    "\n",
    "def baum_welch_stepwise_loggers(sentences, initial_transition, initial_emission, initial_prob, tags, words_dict, alpha=0.9, max_iterations=1000, log_convergence_threshold=np.log(0.01), batch_size=400):\n",
    "    log_transition = np.log(initial_transition)\n",
    "    log_emission = np.log(initial_emission)\n",
    "    log_initial = np.log(initial_prob)\n",
    "\n",
    "    # assert np.all(~np.isneginf(log_transition)), \"Error: transition contains -inf values.\"\n",
    "    # assert np.all(~np.isneginf(log_emission)), \"Error: emission contains -inf values.\"\n",
    "    # assert np.all(~np.isneginf(log_initial)), \"Error: initial contains -inf values.\"\n",
    "\n",
    "    iteration = 0\n",
    "    converged = False\n",
    "    num_sentences = len(sentences)\n",
    "\n",
    "    while iteration < max_iterations and not converged:\n",
    "        np.random.shuffle(sentences)\n",
    "        print(f'Iteration: {iteration}')\n",
    "\n",
    "        for i in range(0, num_sentences, batch_size):\n",
    "            batch = sentences[i:i + batch_size]\n",
    "            batch_log_a1 = []\n",
    "            batch_log_a2 = []\n",
    "            batch_log_b1 = []\n",
    "            batch_log_b2 = []\n",
    "\n",
    "            for sentence in batch:\n",
    "                a1, a2, b1, b2 = baum_log(sentence, log_transition, log_emission, log_initial, tags, words_dict)\n",
    "                batch_log_a1.append(a1)\n",
    "                batch_log_a2.append(a2)\n",
    "                batch_log_b1.append(b1)\n",
    "                batch_log_b2.append(b2)\n",
    "\n",
    "            batch_log_a1 = np.array(batch_log_a1)\n",
    "            batch_log_a2 = np.array(batch_log_a2)\n",
    "            batch_log_b1 = np.array(batch_log_b1)\n",
    "            batch_log_b2 = np.array(batch_log_b2)\n",
    "\n",
    "            # Aggregate updates for the batch\n",
    "            log_af = logsumexp(batch_log_a1, axis=0) - logsumexp(batch_log_a2, axis=0)\n",
    "            log_bf = logsumexp(batch_log_b1, axis=0) - logsumexp(batch_log_b2, axis=0)\n",
    "\n",
    "            # print(f\"{len(batch_log_a)=}\")\n",
    "            # print(f\"{len(batch_log_b)=}\")\n",
    "\n",
    "            # iteration + 2 because (1 - learning_rate) is 0 when iteration is 0\n",
    "            learning_rate = 1 / ((iteration + 2) ** alpha)\n",
    "            lr0, lr1 = np.log(learning_rate), np.log(1 - learning_rate)\n",
    "\n",
    "            # Immediate EM update per batch using weighted average in log space\n",
    "            log_transition = logsumexp([log_transition + lr1, log_af + lr0], axis=0)\n",
    "            log_emission = logsumexp([log_emission + lr1, log_bf + lr0], axis=0)\n",
    "\n",
    "        prev_transition = np.copy(log_transition) if iteration == 0 else prev_transition\n",
    "        prev_emission = np.copy(log_emission) if iteration == 0 else prev_emission\n",
    "\n",
    "        # Check convergence\n",
    "        if np.max(np.abs(log_transition - prev_transition)) < log_convergence_threshold and \\\n",
    "           np.max(np.abs(log_emission - prev_emission)) < log_convergence_threshold:\n",
    "            converged = True\n",
    "\n",
    "        # DEBUGGING PURPOSES: STOP AT 1 ITERATION\n",
    "        # if iteration == 1:\n",
    "        #     converged = True\n",
    "\n",
    "        if iteration == 10:\n",
    "            converged = True\n",
    "\n",
    "        prev_transition = np.copy(log_transition)\n",
    "        prev_emission = np.copy(log_emission)\n",
    "        if iteration % 5 == 0:\n",
    "        # if iteration in range(10):\n",
    "            print(f\"{prev_emission=}\")\n",
    "            print(f\"{prev_transition=}\")\n",
    "        iteration += 1\n",
    "\n",
    "    # Convert back to probabilities if needed for interpretation\n",
    "    transition = np.exp(log_transition)\n",
    "    emission = np.exp(log_emission)\n",
    "\n",
    "    return transition, emission\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 538, 665, 666, 667, 668, 901, 902, 1007, 1013, 1020, 1321, 1471, 1501, 1544, 1674, 1758, 1851, 1859, 2207, 2255, 2259, 3004, 3041, 3048, 3062, 3072, 3083, 3494, 3516, 3534, 3545, 3550, 3572, 3575, 3578, 3908, 4006, 4227, 4323, 4331, 4659, 4874, 4877, 4880, 4883, 4905, 4916, 5448, 5689, 6925, 7728, 7732, 7735, 7771, 8233, 8392, 8393, 8394, 8395, 8511, 8512, 8574, 8932, 8942, 8953, 9165, 9232, 9253, 9415, 9416, 9417, 9418, 9428, 9444, 9478, 9489, 9501, 9665, 9666, 9978, 10128, 10176, 10444, 10543, 10616, 10622, 10626, 10642, 10645, 12023, 12348, 12401, 12406, 12415, 12430, 12453, 12472, 12479, 12519, 13240, 13271, 13289, 13560, 13753, 13921, 13922, 13923, 14034, 14042, 14045, 14140, 14141, 14142, 14281, 14401, 14478, 14737, 15052, 15064, 15377, 15546, 15548, 15563, 15577, 15580, 15687, 16144, 16427, 16485, 16486, 16489, 16753, 16765, 17375, 17376, 17651, 17772, 17779, 17970, 17976, 17979, 18147, 18499, 18528, 18533, 18536, 18906, 18909, 18912, 18967, 18975, 18995, 19078, 19127, 19231, 19246, 19251, 19258, 19526, 19531, 19534, 19979, 19995, 20329, 21005, 21017, 21026, 21034, 21040, 21049, 21094, 21281, 21285, 21356, 21369, 21386, 21394, 21438, 21453, 21464, 21472, 21482, 21492, 22165, 22461, 22571, 23165, 23168, 23194, 23442, 23443, 24364, 24906, 25013, 25135, 25205, 25265, 25274, 25278, 25319, 25322, 25340, 25349, 25967, 25968, 25971, 25973, 25975, 26005, 26224, 26235, 26240, 26374, 26450, 26521, 26522, 26524, 26636, 26985, 27309, 27338, 27530, 27541, 27546, 27598, 27641, 27830, 28033, 28264, 28276, 28281, 28295, 28305, 28311, 28514, 28565, 28792, 28794, 28978, 29774, 29782, 29847, 29859, 29867, 30036, 30273, 30353, 30383, 30386, 30389, 30640, 31076, 31080, 31362, 31437, 31438, 31439, 31442, 31443, 31448, 31449, 31454, 31455, 31461, 31462, 31467, 31468, 31471, 31472, 31477, 31478, 31489, 31490, 31493, 31494, 31498, 31499, 31502, 31503, 31504, 31507, 31508, 31518, 31519, 31524, 31525, 31533, 31534, 31536, 31537, 31542, 31543, 31546, 31547, 31555, 31556, 31558, 31559, 31563, 31564, 31570, 31571, 31572, 31701, 31708, 31717, 31733, 32032, 32036, 32260, 32324, 32325, 32326, 32634, 32652, 32830, 32959, 32969, 32976, 32979, 32982, 33428, 33437, 33567, 33588, 33589, 33810, 33815, 33819, 33829, 33839, 34752, 34886, 34940, 34955, 35019, 35026, 35036, 35043, 35044, 35053, 35072, 35259, 35269, 35326, 35418, 36109, 36215, 36271, 36515, 36516, 36517, 36518, 36842, 36941, 36944, 36947, 36972, 36985, 36996, 37004, 37127, 37141, 37150, 37162, 37232, 37239, 37299, 37313, 37940, 38124, 38340, 38403, 38521, 39231, 39336, 39602, 39638]\n",
      "Iteration: 0\n",
      "prev_emission=array([[-87.23830431, -87.23810356, -83.02918806, ..., -87.23830431,\n",
      "        -87.23830431, -87.23830431],\n",
      "       [-87.57554699, -87.57554699, -87.57553452, ..., -87.57554699,\n",
      "        -87.57554699, -87.57554699],\n",
      "       [-86.62057563, -86.62057542, -86.62057149, ..., -86.62057563,\n",
      "        -86.62057563, -86.62057563],\n",
      "       ...,\n",
      "       [-86.01479598, -81.05194762, -67.67630683, ..., -86.01479598,\n",
      "        -86.01479598, -86.01479598],\n",
      "       [-87.66435984, -87.66435984, -76.012296  , ..., -86.56574755,\n",
      "        -87.66435984, -87.66435984],\n",
      "       [-85.22831299, -85.22830531, -77.69526193, ..., -85.22831299,\n",
      "        -85.22831299, -85.22831299]])\n",
      "prev_transition=array([[ -0.97643396, -19.27390447, -16.29210699, -13.41060184,\n",
      "        -10.3077507 , -29.19805713, -12.96875572, -11.57265944,\n",
      "         -0.51974558,  -8.63347722, -11.17500736,  -5.87693968,\n",
      "         -3.86739224, -21.29467325,  -5.47890085, -16.68513919,\n",
      "         -7.51037588],\n",
      "       [ -1.55136492, -37.37678488, -33.7276177 , -29.09034602,\n",
      "        -29.25100909, -36.60852266, -11.67182645, -30.65235577,\n",
      "         -0.30743233, -22.49028763, -21.9093408 , -22.48083997,\n",
      "         -7.42326302, -36.75660384,  -2.95467084, -29.08929174,\n",
      "        -11.81836784],\n",
      "       [ -1.81481539, -33.41728277, -28.88618866, -20.53629083,\n",
      "        -24.16723427, -35.96695419, -10.13032145, -31.15206554,\n",
      "         -0.19794574, -15.27857216, -19.42042191, -21.20378468,\n",
      "         -5.31772111, -30.17079431,  -4.48118663, -24.71226788,\n",
      "         -7.69812195],\n",
      "       [ -1.81866043, -35.62248276, -24.54198615, -22.14859126,\n",
      "        -23.89596998, -36.90473832,  -6.99564347, -28.7165774 ,\n",
      "         -0.24034073, -13.41819555, -16.75014746, -19.69326293,\n",
      "         -3.5614661 , -33.35286736,  -3.96452568, -21.08828026,\n",
      "         -5.77455575],\n",
      "       [ -1.99089902, -36.2369737 , -28.68992528, -22.79675882,\n",
      "        -29.41174198, -37.14631593, -10.59082159, -29.71810624,\n",
      "         -0.16974133, -17.00506634, -19.16887376, -21.93533934,\n",
      "         -4.91323109, -32.55570085,  -4.41339372, -27.0506875 ,\n",
      "         -9.7822707 ],\n",
      "       [ -1.6775237 , -41.12820394, -36.38404697, -30.76551001,\n",
      "        -33.18539169, -43.8058217 , -11.81481487, -33.06876976,\n",
      "         -0.28771779, -26.01614604, -28.41284324, -24.42069475,\n",
      "         -6.21306184, -41.0595317 ,  -2.79506696, -30.41491009,\n",
      "         -9.57491532],\n",
      "       [ -1.18461619, -26.53840332, -19.16552133, -18.18940068,\n",
      "        -20.75834276, -35.72550613,  -9.39032086, -20.8164564 ,\n",
      "         -0.37179941, -11.8456932 , -14.35230534, -12.87730414,\n",
      "         -6.3821853 , -27.37801069,  -5.86988626, -12.69631917,\n",
      "        -10.33797352],\n",
      "       [ -1.73012516, -30.50673056, -28.53541251, -19.52509414,\n",
      "        -21.22193162, -36.94555834,  -9.87124826, -28.62054074,\n",
      "         -0.23149607, -16.29886576, -18.42329587, -19.80204254,\n",
      "         -6.4819133 , -29.22879601,  -3.59640345, -23.3786668 ,\n",
      "         -7.85662206],\n",
      "       [ -0.60844313, -17.35491537, -14.90025585,  -9.87876557,\n",
      "        -11.19549722, -26.00835604, -11.59091162, -11.59452851,\n",
      "         -0.86518067, -10.20473771,  -9.82448646,  -5.69720019,\n",
      "         -3.63836381, -21.89724048,  -5.33019051, -14.93505827,\n",
      "         -8.75305179],\n",
      "       [ -1.55768717, -29.86562687, -24.3697586 , -17.12977881,\n",
      "        -20.99396607, -32.36061775, -11.2368128 , -23.19823027,\n",
      "         -0.25027088, -18.76228377, -16.58430458, -15.80864825,\n",
      "         -5.28184926, -27.44275766,  -5.17164726, -22.53998234,\n",
      "        -11.05239052],\n",
      "       [ -1.74090784, -33.46220081, -25.02193483, -19.37317118,\n",
      "        -23.2725531 , -35.81406978,  -9.60052419, -26.78245358,\n",
      "         -0.20619295, -16.81485357, -16.574996  , -19.54360322,\n",
      "         -5.48245692, -29.26239736,  -5.07587757, -17.04541997,\n",
      "         -7.62059085],\n",
      "       [ -1.70639332, -29.81287382, -26.47244772, -19.33284795,\n",
      "        -18.97322373, -35.0382366 , -10.09440902, -26.91571427,\n",
      "         -0.21969422, -14.52627737, -16.79857709, -18.68476856,\n",
      "         -5.4008964 , -27.19107985,  -4.69907517, -23.23043555,\n",
      "         -6.18583689],\n",
      "       [ -1.35705906, -28.87789103, -24.43942965, -17.72856391,\n",
      "        -20.31899262, -32.93208637,  -4.5781496 , -24.15586028,\n",
      "         -0.31805407, -20.1447883 , -11.47735059, -13.55563897,\n",
      "         -7.48022591, -26.71066895,  -6.24481731, -24.60298316,\n",
      "         -6.10590924],\n",
      "       [ -1.79934658, -38.34356093, -34.11757364, -26.379223  ,\n",
      "        -31.64924715, -37.51206208,  -8.57989753, -32.91893225,\n",
      "         -0.25259245, -20.53568236, -21.11229606, -24.25427594,\n",
      "         -7.66348707, -33.74847224,  -2.8628332 , -23.98985612,\n",
      "        -10.02181307],\n",
      "       [ -0.77432728, -18.07142764, -16.71250443, -10.9116602 ,\n",
      "        -13.05797427, -26.87848858,  -9.66783462, -14.23282212,\n",
      "         -0.64674288, -12.76266308, -11.59098455,  -6.49917556,\n",
      "         -4.32070022, -22.09285284, -11.39044381, -14.99281933,\n",
      "         -8.0046626 ],\n",
      "       [ -1.81262129, -30.3728977 , -25.88919056, -25.65225899,\n",
      "        -23.55701651, -33.71027803,  -9.64508311, -27.1186748 ,\n",
      "         -0.19835827, -14.93459945, -15.99787327, -20.61876301,\n",
      "         -4.90485257, -28.32207417,  -4.7187411 , -28.33359516,\n",
      "         -8.12457596],\n",
      "       [ -1.29762791, -25.87182348, -20.21508093, -17.47905752,\n",
      "        -19.66317559, -34.3923517 , -10.08043133, -17.90510761,\n",
      "         -0.32555307, -10.25658749, -15.03258356, -12.41836807,\n",
      "         -6.4073553 , -27.39734616,  -5.87332001, -13.17051103,\n",
      "         -8.82569332]])\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "prev_emission=array([[-234.20849805, -234.2082973 ,  -65.20552627, ..., -234.20849805,\n",
      "        -234.20849805, -234.20849805],\n",
      "       [-234.54574073, -234.54574073, -112.424984  , ..., -234.54574073,\n",
      "        -234.54574073, -234.54574073],\n",
      "       [-233.59076937, -233.59076916,  -96.60027048, ..., -233.59076937,\n",
      "        -233.59076937, -233.59076937],\n",
      "       ...,\n",
      "       [-232.98498972, -228.02214136,  -60.94394948, ..., -232.98498972,\n",
      "        -232.98498972, -232.98498972],\n",
      "       [-234.63455358, -234.63455358,  -74.16914123, ..., -233.53594129,\n",
      "        -234.63455358, -234.63455358],\n",
      "       [-232.19850673, -232.19849905,  -48.49642199, ..., -232.19850673,\n",
      "        -232.19850673, -232.19850673]])\n",
      "prev_transition=array([[ -22.77438066,  -90.82455573,  -81.24354405,  -57.55481406,\n",
      "         -50.03201917,  -98.84205431,  -65.92224977,  -80.26723836,\n",
      "          -1.2159031 ,   -3.23947744,  -76.61379909,  -10.186169  ,\n",
      "          -0.40896758,  -90.83350659,  -70.70350407,  -78.71247628,\n",
      "         -54.10562236],\n",
      "       [  -2.26111251, -130.50510438, -116.65915531,  -87.15766182,\n",
      "         -73.84656042, -128.20739768,  -36.08610653, -120.09574516,\n",
      "          -0.90838588,  -19.0826047 , -103.67004009,  -10.76533555,\n",
      "          -0.7081188 , -128.26248922,  -64.50999668,  -92.828202  ,\n",
      "         -29.32560408],\n",
      "       [  -2.26095008, -135.63861173, -121.56739454,  -81.63895068,\n",
      "         -69.97094472, -137.35292571,  -37.33559059, -126.12542376,\n",
      "          -0.90730309,  -13.25702211, -108.02048068,  -10.93785206,\n",
      "          -0.7090371 , -130.51035888,  -70.10283181,  -95.52785206,\n",
      "         -29.295968  ],\n",
      "       [  -4.58907503, -128.31800555, -113.71319063,  -76.44743173,\n",
      "         -67.7187397 , -132.00139842,  -37.77398253, -115.31344567,\n",
      "          -0.78416435,   -8.80956091, -100.1413352 ,  -11.10990774,\n",
      "          -0.62891033, -124.67759264,  -70.1162631 ,  -87.17465842,\n",
      "         -29.37822227],\n",
      "       [  -3.40273942, -131.00406957, -121.3865711 ,  -78.94796071,\n",
      "         -74.31570535, -133.57684783,  -35.67770339, -118.49779666,\n",
      "          -0.8103397 ,  -10.92620217, -104.55703835,  -11.90050601,\n",
      "          -0.65011396, -125.24522785,  -72.85599005,  -92.75789653,\n",
      "         -35.23339221],\n",
      "       [  -5.3799937 , -131.99829294, -117.01145515,  -85.02970427,\n",
      "         -77.11759646, -132.83701718,  -31.72577152, -118.58706506,\n",
      "          -0.77740627,  -23.72779947, -105.79708431,  -10.00755761,\n",
      "          -0.62408661, -129.89930688,  -65.47614293,  -94.40253885,\n",
      "         -28.82251488],\n",
      "       [  -7.85931917, -107.27369469,  -93.24853436,  -70.62337892,\n",
      "         -62.5593908 , -118.1813892 ,  -51.02901162,  -99.31151767,\n",
      "          -0.8140339 ,   -9.04575899,  -78.46034086,  -11.41710874,\n",
      "          -0.58623583, -108.29672367,  -75.11870662,  -74.96812888,\n",
      "         -31.00671345],\n",
      "       [  -2.26125223, -127.21242891, -115.80666614,  -80.94892613,\n",
      "         -66.87552614, -133.38265903,  -31.894354  , -121.65840969,\n",
      "          -0.90882212,  -17.5791165 , -104.86295274,  -10.85817793,\n",
      "          -0.70772856, -124.39700332,  -70.56511524,  -92.96852345,\n",
      "         -29.42709193],\n",
      "       [ -13.87847453,  -76.33609247,  -65.35633266,  -40.70356896,\n",
      "         -38.73619373,  -79.29873137,  -54.09598912,  -67.8105046 ,\n",
      "          -1.60984415,   -1.79442598,  -59.84051377,   -6.64994584,\n",
      "          -0.45797489,  -77.93656198,  -59.80520325,  -66.61116288,\n",
      "         -49.75783933],\n",
      "       [  -8.79349457,  -88.06497587,  -74.23726062,  -37.09406607,\n",
      "         -38.52657177,  -87.54175833,  -46.24553645,  -79.83547295,\n",
      "          -1.09847362,  -13.87249454,  -64.18057812,   -9.92711464,\n",
      "          -0.40583676,  -84.50295405,  -48.63078912,  -68.55060951,\n",
      "         -48.01382047],\n",
      "       [  -2.31221632, -133.94217788, -115.61707708,  -80.82240271,\n",
      "         -69.49776842, -135.63436443,  -29.5722926 , -121.96436645,\n",
      "          -0.8973266 ,  -15.51115616, -104.96557727,  -10.56991418,\n",
      "          -0.70668926, -128.29311698,  -70.84612551,  -88.55503231,\n",
      "         -29.86674191],\n",
      "       [  -7.64992368, -102.37398432,  -96.54645024,  -60.244273  ,\n",
      "         -59.18153794, -106.24724787,  -52.84698189,  -96.19446337,\n",
      "          -0.92635263,  -12.98466483,  -78.63505733,  -24.55986684,\n",
      "          -0.50496582,  -98.04589221,  -58.88235385,  -72.8492997 ,\n",
      "         -46.97157514],\n",
      "       [  -8.69978623,  -89.62164489,  -71.68905217,  -37.65811811,\n",
      "         -37.35639766,  -88.41081085,  -45.45001568,  -80.87476639,\n",
      "          -1.05825474,  -10.58808714,  -57.16985884,   -7.21589345,\n",
      "          -0.42769177,  -85.10799459,  -58.9573237 ,  -72.09579938,\n",
      "         -46.60215483],\n",
      "       [  -2.26140492, -130.56788552, -115.61207342,  -83.37895213,\n",
      "         -76.36288859, -127.3034325 ,  -31.42178739, -119.55471468,\n",
      "          -0.90928488,  -16.92714286, -100.59814824,  -10.80226799,\n",
      "          -0.70732027, -124.96620399,  -73.17435397,  -87.0330143 ,\n",
      "         -29.48553958],\n",
      "       [  -3.73938158, -113.92050074, -103.39700113,  -76.63553901,\n",
      "         -69.18137551, -122.31253978,  -40.71539966, -104.39279019,\n",
      "          -0.79166041,  -15.92278481,  -96.86605031,   -9.60265618,\n",
      "          -0.64803677, -115.29413736,  -87.92959118,  -86.93935201,\n",
      "         -26.5801709 ],\n",
      "       [  -5.68381587, -130.80052615, -117.48318935,  -84.98945198,\n",
      "         -66.08166941, -133.63850996,  -29.53237409, -121.81022725,\n",
      "          -0.77880136,   -9.79208598, -104.53104312,  -10.61162557,\n",
      "          -0.6207091 , -127.49877779,  -76.18015504,  -98.9553821 ,\n",
      "         -30.88266239],\n",
      "       [  -7.93190038, -107.17060506,  -94.2805961 ,  -71.32555408,\n",
      "         -64.66779383, -117.51697979,  -51.15522098,  -95.30926027,\n",
      "          -0.81152753,   -8.28946767,  -80.02236679,  -11.51105255,\n",
      "          -0.58842565, -108.91428489,  -80.35386932,  -75.01149945,\n",
      "         -42.36264176]])\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "Iteration: 10\n",
      "prev_emission=array([[-302.16359754, -302.15420817,  -19.66694289, ..., -302.16359754,\n",
      "        -302.16359754, -302.16359754],\n",
      "       [-302.50084022, -302.49666356,  -75.88499558, ..., -302.50084022,\n",
      "        -302.50084022, -302.50084022],\n",
      "       [-301.54586886, -301.54046773,  -49.65364152, ..., -301.54586886,\n",
      "        -301.54586886, -301.54586886],\n",
      "       ...,\n",
      "       [-300.94008921, -295.97223011,  -14.10402557, ..., -300.94008921,\n",
      "        -300.94008921, -300.94008921],\n",
      "       [-302.58965307, -302.58446846,  -26.81555745, ..., -301.49104078,\n",
      "        -302.58965307, -302.58965307],\n",
      "       [-300.15360622, -300.15342965,  -24.6698715 , ..., -300.15360622,\n",
      "        -300.15360622, -300.15360622]])\n",
      "prev_transition=array([[-4.49854062e+01, -1.29821474e+02, -1.20397684e+02,\n",
      "        -9.64979641e+01, -8.95595385e+01, -1.39463672e+02,\n",
      "        -1.05831329e+02, -1.18764770e+02, -1.12440488e+00,\n",
      "        -2.00971309e+01, -1.15952272e+02, -4.56739618e+01,\n",
      "        -3.92814070e-01, -1.31260593e+02, -1.10850770e+02,\n",
      "        -1.16954849e+02, -9.22379067e+01],\n",
      "       [-6.60769826e+00, -1.74452171e+02, -1.60587309e+02,\n",
      "        -1.31459678e+02, -1.18609581e+02, -1.73313623e+02,\n",
      "        -5.21222557e+01, -1.63386921e+02, -9.46537721e-01,\n",
      "        -1.08990235e+01, -1.48279082e+02, -5.01675691e+01,\n",
      "        -4.93396336e-01, -1.73343345e+02, -1.08730623e+02,\n",
      "        -1.36383890e+02, -2.81400496e+01],\n",
      "       [-6.63904698e+00, -1.79657109e+02, -1.65545657e+02,\n",
      "        -1.26021341e+02, -1.14808244e+02, -1.82525421e+02,\n",
      "        -5.84929567e+01, -1.69489555e+02, -9.47032868e-01,\n",
      "        -1.06866250e+01, -1.52702916e+02, -5.03866101e+01,\n",
      "        -4.93020679e-01, -1.75655646e+02, -1.14378440e+02,\n",
      "        -1.39145470e+02, -3.10829461e+01],\n",
      "       [-6.56049390e+00, -1.71232180e+02, -1.56518388e+02,\n",
      "        -1.19142784e+02, -1.10921257e+02, -1.76082878e+02,\n",
      "        -7.41873529e+01, -1.57668831e+02, -9.69789135e-01,\n",
      "        -2.29926881e+01, -1.43226004e+02, -4.97710600e+01,\n",
      "        -4.78968766e-01, -1.68680614e+02, -1.13322573e+02,\n",
      "        -1.29507596e+02, -5.31654303e+01],\n",
      "       [-6.57876147e+00, -1.73960492e+02, -1.64223930e+02,\n",
      "        -1.21686964e+02, -1.17557020e+02, -1.77700815e+02,\n",
      "        -7.17825467e+01, -1.60896650e+02, -9.66425751e-01,\n",
      "        -2.51173702e+01, -1.47676766e+02, -5.05870823e+01,\n",
      "        -4.80991728e-01, -1.69288219e+02, -1.16086736e+02,\n",
      "        -1.35131716e+02, -5.87892833e+01],\n",
      "       [-6.61511082e+00, -1.76061180e+02, -1.61048363e+02,\n",
      "        -1.29509663e+02, -1.22053944e+02, -1.78055662e+02,\n",
      "        -4.46279501e+01, -1.61992621e+02, -9.46822304e-01,\n",
      "        -1.05805317e+01, -1.50572420e+02, -4.95055569e+01,\n",
      "        -4.93210511e-01, -1.75090648e+02, -1.09858707e+02,\n",
      "        -1.38076105e+02, -2.42827972e+01],\n",
      "       [-6.69019475e+00, -1.50455621e+02, -1.36412489e+02,\n",
      "        -1.13982799e+02, -1.06389363e+02, -1.62538642e+02,\n",
      "        -7.78478763e+01, -1.41935762e+02, -9.44577926e-01,\n",
      "        -2.28595016e+01, -1.22113913e+02, -5.00250982e+01,\n",
      "        -4.94438460e-01, -1.52605282e+02, -1.18634781e+02,\n",
      "        -1.17897943e+02, -4.53910182e+01],\n",
      "       [-6.55772284e+00, -1.70898474e+02, -1.59445915e+02,\n",
      "        -1.24851140e+02, -1.11240907e+02, -1.78217031e+02,\n",
      "        -5.02161601e+01, -1.64687446e+02, -9.40557760e-01,\n",
      "        -1.75177850e+01, -1.49078191e+02, -5.01066540e+01,\n",
      "        -4.97299446e-01, -1.69193793e+02, -1.14406309e+02,\n",
      "        -1.36234917e+02, -2.93558185e+01],\n",
      "       [-3.39686504e+01, -1.05160678e+02, -9.43219311e+01,\n",
      "        -6.83924198e+01, -6.71743123e+01, -1.09915560e+02,\n",
      "        -8.47533569e+01, -9.63463622e+01, -1.23236024e+01,\n",
      "        -2.15043827e+01, -8.82750189e+01, -3.07027737e+01,\n",
      "        -4.44603816e-06, -1.08244547e+02, -8.97741009e+01,\n",
      "        -9.47708112e+01, -7.88937217e+01],\n",
      "       [-6.73668776e+00, -1.19886013e+02, -1.06275688e+02,\n",
      "        -6.77151071e+01, -6.99936199e+01, -1.20796918e+02,\n",
      "        -7.87820315e+01, -1.10881016e+02, -1.11346156e+00,\n",
      "        -3.34585281e+01, -9.56671461e+01, -4.06838276e+01,\n",
      "        -3.99890746e-01, -1.17588621e+02, -7.98796726e+01,\n",
      "        -9.99659322e+01, -7.82543247e+01],\n",
      "       [-6.60482089e+00, -1.77250833e+02, -1.58851224e+02,\n",
      "        -1.24154376e+02, -1.13304770e+02, -1.80091649e+02,\n",
      "        -5.04175738e+01, -1.64723382e+02, -9.43358460e-01,\n",
      "        -2.94316685e+01, -1.48675133e+02, -4.94884587e+01,\n",
      "        -4.95398492e-01, -1.72708767e+02, -1.14547176e+02,\n",
      "        -1.31342169e+02, -3.11513636e+01],\n",
      "       [-6.83001011e+00, -1.41936965e+02, -1.36089328e+02,\n",
      "        -9.95312110e+01, -9.90554709e+01, -1.47179507e+02,\n",
      "        -9.31986845e+01, -1.35222685e+02, -1.08284957e+00,\n",
      "        -2.33537817e+01, -1.18349669e+02, -6.08321254e+01,\n",
      "        -4.15076219e-01, -1.38767712e+02, -9.91933399e+01,\n",
      "        -1.11834057e+02, -8.54053861e+01],\n",
      "       [-1.94988628e+01, -1.10886316e+02, -9.30385149e+01,\n",
      "        -5.69110267e+01, -5.72063587e+01, -1.11690595e+02,\n",
      "        -6.81779740e+01, -1.02380278e+02, -1.97944611e+00,\n",
      "        -2.74339702e+01, -7.71764502e+01, -2.82678720e+01,\n",
      "        -1.48669090e-01, -1.07865752e+02, -8.07992604e+01,\n",
      "        -9.25212342e+01, -6.82892140e+01],\n",
      "       [-6.62399315e+00, -1.74607265e+02, -1.59627863e+02,\n",
      "        -1.27836779e+02, -1.21275680e+02, -1.72499557e+02,\n",
      "        -4.73896588e+01, -1.62937400e+02, -9.46844669e-01,\n",
      "        -1.05794635e+01, -1.45351240e+02, -5.02666940e+01,\n",
      "        -4.93176943e-01, -1.70136175e+02, -1.17529460e+02,\n",
      "        -1.30688391e+02, -2.83861548e+01],\n",
      "       [-6.62622856e+00, -1.57374729e+02, -1.46796628e+02,\n",
      "        -1.20186773e+02, -1.13206285e+02, -1.66909149e+02,\n",
      "        -6.19499639e+01, -1.47293591e+02, -9.43330816e-01,\n",
      "        -2.83531180e+01, -1.40729918e+02, -4.85071773e+01,\n",
      "        -4.95369097e-01, -1.59857833e+02, -1.31764295e+02,\n",
      "        -1.29946972e+02, -3.54805308e+01],\n",
      "       [-6.58323672e+00, -1.74660257e+02, -1.61291126e+02,\n",
      "        -1.29100900e+02, -1.10647436e+02, -1.78641596e+02,\n",
      "        -5.07646084e+01, -1.65012037e+02, -9.41392558e-01,\n",
      "        -1.57730021e+01, -1.48940959e+02, -5.00461083e+01,\n",
      "        -4.96705365e-01, -1.72467769e+02, -1.20208527e+02,\n",
      "        -1.42403624e+02, -2.90309313e+01],\n",
      "       [-6.66346788e+00, -1.50290546e+02, -1.37471511e+02,\n",
      "        -1.14716652e+02, -1.08537962e+02, -1.61841452e+02,\n",
      "        -7.75794058e+01, -1.37764948e+02, -9.37485538e-01,\n",
      "        -2.14771090e+01, -1.23727417e+02, -5.02651480e+01,\n",
      "        -4.99041994e-01, -1.53195060e+02, -1.23906534e+02,\n",
      "        -1.17950196e+02, -5.59189773e+01]])\n"
     ]
    }
   ],
   "source": [
    "# Filter out sentences of length 1\n",
    "# Note: This is AFTER using them to make emission and initial matrices\n",
    "bad_list = [i for i, p in enumerate(processed_sentences) if len(p) < 4]\n",
    "[p for i, p in enumerate(processed_sentences) if i not in bad_list]\n",
    "print(bad_list)\n",
    "processed_sentences_cleaned = [p for i, p in enumerate(processed_sentences) if i not in bad_list]\n",
    "\n",
    "transition, emission = baum_welch_stepwise_loggers(processed_sentences_cleaned, t_matrix, e_matrix, initial, unique_upos, unique_words_dict)\n",
    "# cProfile.run(\"baum_welch_stepwise_loggers(random.sample(processed_sentences_cleaned, 4000), t_matrix, e_matrix, initial, unique_upos, unique_words_dict, batch_size=400)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(list(zip(processed_sentences[:50], processed_tags[:50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.90460004e-20 4.16150215e-57 5.15169403e-53 1.23443056e-42\n",
      "  1.27287751e-39 2.70207164e-61 1.09153523e-46 2.63703537e-52\n",
      "  3.24845731e-01 1.87036759e-09 4.39104738e-51 1.45898360e-20\n",
      "  6.75154267e-01 9.86844931e-58 7.21310322e-49 1.61121775e-51\n",
      "  8.74150245e-41]\n",
      " [1.34993578e-03 1.72339443e-76 1.81058088e-70 8.08699417e-58\n",
      "  3.07973444e-52 5.38083570e-76 2.30989349e-23 1.10144295e-71\n",
      "  3.88082349e-01 1.84762681e-05 4.01063378e-65 1.63117878e-22\n",
      "  6.10549239e-01 5.22326088e-76 6.01021939e-48 5.87799150e-60\n",
      "  6.01079224e-13]\n",
      " [1.30827347e-03 9.46038972e-79 1.27184629e-72 1.86048767e-55\n",
      "  1.37852035e-50 5.37299965e-80 3.95213422e-26 2.46389099e-74\n",
      "  3.87890239e-01 2.28485029e-05 4.80801766e-67 1.31030759e-22\n",
      "  6.10778639e-01 5.17275755e-77 2.11872512e-50 3.71441408e-61\n",
      "  3.16845865e-14]\n",
      " [1.41518658e-03 4.31329252e-75 1.05907756e-68 1.80695129e-52\n",
      "  6.72218106e-49 3.37425396e-77 6.03728979e-33 3.35194513e-69\n",
      "  3.79162982e-01 1.03371888e-10 6.27677928e-63 2.42495284e-22\n",
      "  6.19421832e-01 5.53273587e-74 6.09020735e-50 5.69594641e-57\n",
      "  8.13854898e-24]\n",
      " [1.38956925e-03 2.81785118e-76 4.76928807e-72 1.41913309e-53\n",
      "  8.82338010e-52 6.69139116e-78 6.68707339e-32 1.32884039e-70\n",
      "  3.80440400e-01 1.23499361e-11 7.32479481e-65 1.07228274e-22\n",
      "  6.18170031e-01 3.01342746e-74 3.83858488e-51 2.05608729e-59\n",
      "  2.93858778e-26]\n",
      " [1.33996629e-03 3.44826743e-77 1.14178574e-70 5.68418325e-57\n",
      "  9.83208208e-54 4.69254504e-78 4.15267127e-20 4.44118441e-71\n",
      "  3.87971923e-01 2.54058346e-05 4.04789039e-66 3.16234926e-22\n",
      "  6.10662704e-01 9.10117873e-77 1.94522532e-48 1.08220488e-60\n",
      "  2.84521543e-11]\n",
      " [1.24304067e-03 4.54939817e-66 5.71227259e-60 3.14702017e-50\n",
      "  6.24721675e-47 2.57255446e-71 1.55273334e-34 2.28077124e-62\n",
      "  3.88843657e-01 1.18098562e-10 9.25979868e-54 1.88094419e-22\n",
      "  6.09913302e-01 5.30112516e-67 3.00309749e-52 6.27442492e-52\n",
      "  1.93611557e-20]\n",
      " [1.41911359e-03 6.02193123e-75 5.66916267e-70 5.99568545e-55\n",
      "  4.88301466e-49 3.99325366e-78 1.55381304e-22 3.00020512e-72\n",
      "  3.90410019e-01 2.46673572e-08 1.80369899e-65 1.73363096e-22\n",
      "  6.08170842e-01 3.31183837e-74 2.06049459e-50 6.82224303e-60\n",
      "  1.78209155e-13]\n",
      " [1.76848994e-15 2.13450877e-46 1.08769163e-41 1.98403569e-30\n",
      "  6.70759511e-30 1.83771765e-48 1.55626943e-37 1.43650304e-42\n",
      "  4.44557033e-06 4.57894328e-10 4.59881970e-39 4.63398680e-14\n",
      "  9.99995554e-01 9.77215573e-48 1.02707789e-39 6.94319944e-42\n",
      "  5.45622174e-35]\n",
      " [1.18657086e-03 8.59341693e-53 6.99930749e-47 3.90573366e-30\n",
      "  4.00089473e-31 3.45592995e-53 6.10096351e-35 6.99820320e-49\n",
      "  3.28420144e-01 2.94541090e-15 2.83325955e-42 2.14406614e-18\n",
      "  6.70393285e-01 8.54890768e-52 2.03563061e-35 3.84899416e-44\n",
      "  1.03413820e-34]\n",
      " [1.35382564e-03 1.04940047e-77 1.02751893e-69 1.20348242e-54\n",
      "  6.19960099e-50 6.12618960e-79 1.27035739e-22 2.89430269e-72\n",
      "  3.89318128e-01 1.65191915e-13 2.69904599e-65 3.21688454e-22\n",
      "  6.09328046e-01 9.85225470e-76 1.78975488e-50 9.09537846e-58\n",
      "  2.95892997e-14]\n",
      " [1.08084719e-03 2.27802938e-62 7.89143183e-60 5.94489643e-44\n",
      "  9.56655515e-44 1.20434847e-64 3.34445696e-41 1.87730251e-59\n",
      "  3.38629201e-01 7.20412915e-11 3.99385046e-52 3.81016361e-27\n",
      "  6.60289952e-01 5.41936637e-61 8.33450555e-44 2.69827459e-49\n",
      "  8.10796909e-38]\n",
      " [3.40213456e-09 6.96121414e-49 3.92542224e-41 1.92245032e-25\n",
      "  1.43084992e-25 3.11451849e-49 2.45856731e-30 3.44199323e-45\n",
      "  1.38145733e-01 1.21780599e-12 3.03874013e-34 5.28955552e-13\n",
      "  8.61854264e-01 1.42724630e-47 8.11572022e-36 6.58473840e-41\n",
      "  2.19973916e-30]\n",
      " [1.32811698e-03 1.47580318e-76 4.72606611e-70 3.02825325e-56\n",
      "  2.14112184e-53 1.21449072e-75 2.62381191e-21 1.72657758e-71\n",
      "  3.87963247e-01 2.54329881e-05 7.49477320e-64 1.47724377e-22\n",
      "  6.10683203e-01 1.29061848e-74 9.06993712e-52 1.74885067e-57\n",
      "  4.69947793e-13]\n",
      " [1.32515140e-03 4.49804125e-69 1.76617736e-64 6.36132773e-53\n",
      "  6.84124398e-50 3.25295250e-73 1.24586945e-27 1.07449930e-64\n",
      "  3.89328890e-01 4.85732666e-13 7.61681093e-62 8.58223781e-22\n",
      "  6.09345958e-01 3.75513280e-70 5.96339897e-58 3.67068401e-57\n",
      "  3.89943123e-16]\n",
      " [1.38336448e-03 1.39963329e-76 8.95681900e-71 8.55443526e-57\n",
      "  8.83953149e-49 2.61180389e-78 8.97864260e-23 2.16861648e-72\n",
      "  3.90084242e-01 1.41212207e-07 2.06901468e-65 1.84183754e-22\n",
      "  6.08532252e-01 1.25371750e-75 6.22443504e-53 1.42853787e-62\n",
      "  2.46619116e-13]\n",
      " [1.27671121e-03 5.36593371e-66 1.98098586e-60 1.51074532e-50\n",
      "  7.28722413e-48 5.16595560e-71 2.03091686e-34 1.47721360e-60\n",
      "  3.91611290e-01 4.70554652e-10 1.84444430e-54 1.47952939e-22\n",
      "  6.07111998e-01 2.93921239e-67 1.54197029e-54 5.95498603e-52\n",
      "  5.18437868e-25]]\n",
      "[[5.91584734e-132 5.97165499e-132 2.87577714e-009 ... 5.91584734e-132\n",
      "  5.91584734e-132 5.91584734e-132]\n",
      " [4.22235089e-132 4.24002310e-132 1.10551632e-033 ... 4.22235089e-132\n",
      "  4.22235089e-132 4.22235089e-132]\n",
      " [1.09721848e-131 1.10316073e-131 2.72707750e-022 ... 1.09721848e-131\n",
      "  1.09721848e-131 1.09721848e-131]\n",
      " ...\n",
      " [2.01085091e-131 2.88997222e-129 7.49375554e-007 ... 2.01085091e-131\n",
      "  2.01085091e-131 2.01085091e-131]\n",
      " [3.86352202e-132 3.88360488e-132 2.26022341e-012 ... 1.15905661e-131\n",
      "  3.86352202e-132 3.86352202e-132]\n",
      " [4.41514627e-131 4.41592592e-131 1.93201698e-011 ... 4.41514627e-131\n",
      "  4.41514627e-131 4.41514627e-131]]\n"
     ]
    }
   ],
   "source": [
    "# NUMERICAL SPACE\n",
    "print(transition)\n",
    "print(emission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path={(1, 1): np.int64(8), (2, 1): np.int64(12), (3, 1): np.int64(12), (4, 1): np.int64(12), (5, 1): np.int64(8), (6, 1): np.int64(12), (7, 1): np.int64(8), (8, 1): np.int64(12), (9, 1): np.int64(8), (10, 1): np.int64(12), (11, 1): np.int64(12), (12, 1): np.int64(12), (13, 1): np.int64(12), (14, 1): np.int64(12), (15, 1): np.int64(12), (16, 1): np.int64(12), (1, 2): np.int64(8), (2, 2): np.int64(12), (3, 2): np.int64(12), (4, 2): np.int64(12), (5, 2): np.int64(12), (6, 2): np.int64(12), (7, 2): np.int64(8), (8, 2): np.int64(12), (9, 2): np.int64(8), (10, 2): np.int64(12), (11, 2): np.int64(12), (12, 2): np.int64(12), (13, 2): np.int64(12), (14, 2): np.int64(12), (15, 2): np.int64(12), (16, 2): np.int64(12), (1, 3): np.int64(8), (2, 3): np.int64(12), (3, 3): np.int64(12), (4, 3): np.int64(12), (5, 3): np.int64(8), (6, 3): np.int64(12), (7, 3): np.int64(8), (8, 3): np.int64(12), (9, 3): np.int64(8), (10, 3): np.int64(12), (11, 3): np.int64(12), (12, 3): np.int64(8), (13, 3): np.int64(8), (14, 3): np.int64(12), (15, 3): np.int64(12), (16, 3): np.int64(12), (1, 4): np.int64(0), (2, 4): np.int64(0), (3, 4): np.int64(0), (4, 4): np.int64(0), (5, 4): np.int64(0), (6, 4): np.int64(0), (7, 4): np.int64(0), (8, 4): np.int64(0), (9, 4): np.int64(0), (10, 4): np.int64(0), (11, 4): np.int64(0), (12, 4): np.int64(0), (13, 4): np.int64(0), (14, 4): np.int64(0), (15, 4): np.int64(0), (16, 4): np.int64(0), (1, 5): np.int64(0), (2, 5): np.int64(0), (3, 5): np.int64(0), (4, 5): np.int64(0), (5, 5): np.int64(0), (6, 5): np.int64(0), (7, 5): np.int64(0), (8, 5): np.int64(0), (9, 5): np.int64(0), (10, 5): np.int64(0), (11, 5): np.int64(0), (12, 5): np.int64(0), (13, 5): np.int64(0), (14, 5): np.int64(0), (15, 5): np.int64(0), (16, 5): np.int64(0), (1, 6): np.int64(0), (2, 6): np.int64(0), (3, 6): np.int64(0), (4, 6): np.int64(0), (5, 6): np.int64(0), (6, 6): np.int64(0), (7, 6): np.int64(0), (8, 6): np.int64(0), (9, 6): np.int64(0), (10, 6): np.int64(0), (11, 6): np.int64(0), (12, 6): np.int64(0), (13, 6): np.int64(0), (14, 6): np.int64(0), (15, 6): np.int64(0), (16, 6): np.int64(0), (1, 7): np.int64(0), (2, 7): np.int64(0), (3, 7): np.int64(0), (4, 7): np.int64(0), (5, 7): np.int64(0), (6, 7): np.int64(0), (7, 7): np.int64(0), (8, 7): np.int64(0), (9, 7): np.int64(0), (10, 7): np.int64(0), (11, 7): np.int64(0), (12, 7): np.int64(0), (13, 7): np.int64(0), (14, 7): np.int64(0), (15, 7): np.int64(0), (16, 7): np.int64(0), (1, 8): np.int64(0), (2, 8): np.int64(0), (3, 8): np.int64(0), (4, 8): np.int64(0), (5, 8): np.int64(0), (6, 8): np.int64(0), (7, 8): np.int64(0), (8, 8): np.int64(0), (9, 8): np.int64(0), (10, 8): np.int64(0), (11, 8): np.int64(0), (12, 8): np.int64(0), (13, 8): np.int64(0), (14, 8): np.int64(0), (15, 8): np.int64(0), (16, 8): np.int64(0), (1, 9): np.int64(0), (2, 9): np.int64(0), (3, 9): np.int64(0), (4, 9): np.int64(0), (5, 9): np.int64(0), (6, 9): np.int64(0), (7, 9): np.int64(0), (8, 9): np.int64(0), (9, 9): np.int64(0), (10, 9): np.int64(0), (11, 9): np.int64(0), (12, 9): np.int64(0), (13, 9): np.int64(0), (14, 9): np.int64(0), (15, 9): np.int64(0), (16, 9): np.int64(0), (1, 10): np.int64(0), (2, 10): np.int64(0), (3, 10): np.int64(0), (4, 10): np.int64(0), (5, 10): np.int64(0), (6, 10): np.int64(0), (7, 10): np.int64(0), (8, 10): np.int64(0), (9, 10): np.int64(0), (10, 10): np.int64(0), (11, 10): np.int64(0), (12, 10): np.int64(0), (13, 10): np.int64(0), (14, 10): np.int64(0), (15, 10): np.int64(0), (16, 10): np.int64(0), (1, 11): np.int64(0), (2, 11): np.int64(0), (3, 11): np.int64(0), (4, 11): np.int64(0), (5, 11): np.int64(0), (6, 11): np.int64(0), (7, 11): np.int64(0), (8, 11): np.int64(0), (9, 11): np.int64(0), (10, 11): np.int64(0), (11, 11): np.int64(0), (12, 11): np.int64(0), (13, 11): np.int64(0), (14, 11): np.int64(0), (15, 11): np.int64(0), (16, 11): np.int64(0), (1, 12): np.int64(0), (2, 12): np.int64(0), (3, 12): np.int64(0), (4, 12): np.int64(0), (5, 12): np.int64(0), (6, 12): np.int64(0), (7, 12): np.int64(0), (8, 12): np.int64(0), (9, 12): np.int64(0), (10, 12): np.int64(0), (11, 12): np.int64(0), (12, 12): np.int64(0), (13, 12): np.int64(0), (14, 12): np.int64(0), (15, 12): np.int64(0), (16, 12): np.int64(0), (1, 13): np.int64(0), (2, 13): np.int64(0), (3, 13): np.int64(0), (4, 13): np.int64(0), (5, 13): np.int64(0), (6, 13): np.int64(0), (7, 13): np.int64(0), (8, 13): np.int64(0), (9, 13): np.int64(0), (10, 13): np.int64(0), (11, 13): np.int64(0), (12, 13): np.int64(0), (13, 13): np.int64(0), (14, 13): np.int64(0), (15, 13): np.int64(0), (16, 13): np.int64(0), (1, 14): np.int64(0), (2, 14): np.int64(0), (3, 14): np.int64(0), (4, 14): np.int64(0), (5, 14): np.int64(0), (6, 14): np.int64(0), (7, 14): np.int64(0), (8, 14): np.int64(0), (9, 14): np.int64(0), (10, 14): np.int64(0), (11, 14): np.int64(0), (12, 14): np.int64(0), (13, 14): np.int64(0), (14, 14): np.int64(0), (15, 14): np.int64(0), (16, 14): np.int64(0)}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(np.int64(0), 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m sentence \u001b[38;5;241m=\u001b[39m processed_sentences[\u001b[38;5;241m20\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Generate tags\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m tagss \u001b[38;5;241m=\u001b[39m \u001b[43mviterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_upos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sentence, tagss)))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# print(tags)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# print(len(tags))\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# print(unique_upos_dict)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[45], line 22\u001b[0m, in \u001b[0;36mviterbi\u001b[0;34m(observations, num_states, transition_prob, emission_prob)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(observations) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     last_state \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m     optimal_path\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, last_state)\n\u001b[1;32m     25\u001b[0m optimal_path\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: (np.int64(0), 14)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def viterbi(observations, num_states, transition_prob, emission_prob):\n",
    "    V = np.zeros((num_states, len(observations)))\n",
    "    path = {}\n",
    "    # first column of V is the transition prob from state 0\n",
    "    V[:, 0] = transition_prob[0, :]\n",
    "\n",
    "    for t in range(1, len(observations)):\n",
    "        for s in range(1, num_states):\n",
    "            prob = V[:, t - 1] * transition_prob[:, s] * emission_prob[s - 1, unique_words_dict[observations[t]]]\n",
    "            V[s, t] = np.max(prob)\n",
    "            path[s, t] = np.argmax(prob)\n",
    "\n",
    "    optimal_path = []\n",
    "    last_state = np.argmax(V[:, -1])\n",
    "    optimal_path.append(last_state)\n",
    "\n",
    "    print(f\"{path=}\")\n",
    "\n",
    "    for t in range(len(observations) - 1, 1, -1):\n",
    "        last_state = path[last_state, t]\n",
    "        optimal_path.insert(0, last_state)\n",
    "\n",
    "    optimal_path.insert(0, 0)\n",
    "\n",
    "    return optimal_path\n",
    "\n",
    "# Example usage\n",
    "# unique_upos_dict\n",
    "# unique_words_dict\n",
    "log_transition = np.log(transition)\n",
    "log_emission = np.log(emission)\n",
    "sentence = processed_sentences[20]\n",
    "\n",
    "# Generate tags\n",
    "tagss = viterbi(sentence, len(unique_upos), transition, emission)\n",
    "print(list(zip(sentence, tagss)))\n",
    "# print(tags)\n",
    "# print(len(tags))\n",
    "# print(unique_upos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transition probabilities\n",
    "t = np.array([[0.8,0.1],\n",
    "                       [0.1,0.8]])\n",
    "#Emission probabilities\n",
    "e = np.array([[0.1,0.2,0.7],\n",
    "                     [0.7,0.2,0.1]])\n",
    "\n",
    "#defining states and sequence symbols\n",
    "states = ['H','C']\n",
    "states_dic = {'H':0, 'C':1}\n",
    "sequence_syms = {'1':0,'2':1,'3':2}\n",
    "sequence = ['1','2','3']\n",
    "\n",
    "#test sequence\n",
    "test_sequence = '331122313'\n",
    "test_sequence = [x for x in test_sequence]\n",
    "\n",
    "#probabilities of going to end state\n",
    "end_probs = [0.1, 0.1]\n",
    "#probabilities of going from start state\n",
    "start_probs = [0.5, 0.5]\n",
    "\n",
    "newt, newe = baum_welch_stepwise_loggers([test_sequence], t, e, start_probs, states, sequence_syms, batch_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newt)\n",
    "print(newe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
