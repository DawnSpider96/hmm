{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_si_probs(num_tags, word_indices, log_forward, log_backward, log_forward_val, transition, emission):\n",
    "    si_probabilities = np.full((num_tags, len(word_indices)-1, num_tags), -np.inf)\n",
    "\n",
    "    for i in range(len(word_indices)-1):\n",
    "        for j in range(num_tags):\n",
    "            for k in range(num_tags):\n",
    "                si_probabilities[j, i, k] = (\n",
    "                    log_forward[j, i] +\n",
    "                    log_backward[k, i+1] +\n",
    "                    transition[j, k] +\n",
    "                    emission[k, word_indices[i+1]] -\n",
    "                    log_forward_val\n",
    "                )\n",
    "    return si_probabilities\n",
    "\n",
    "\n",
    "\n",
    "def log_si_probs_vec(log_forward, log_backward, log_forward_val, transition, log_emission_sentence):\n",
    "    \"\"\"\n",
    "    Vectorized implementation of log_si_probs function.\n",
    "    \n",
    "    Parameters:\n",
    "    - tags: List of possible tags\n",
    "    - word_indices: Sequence of word indices\n",
    "    - log_forward: Log forward probabilities\n",
    "    - log_backward: Log backward probabilities\n",
    "    - log_forward_val: Log forward value\n",
    "    - transition: Transition log probabilities matrix\n",
    "    - emission: Emission log probabilities matrix\n",
    "    \n",
    "    Returns:\n",
    "    - si_probabilities: Vectorized log probabilities tensor\n",
    "    \"\"\"\n",
    "    # Determine dimensions\n",
    "    # num_tags = len(tags)\n",
    "    # num_words = len(word_indices) - 1\n",
    "    \n",
    "    # # Create the output tensor filled with -inf\n",
    "    # si_probabilities = np.full((num_tags, num_words, num_tags), -np.inf)\n",
    "    \n",
    "    # Compute the log probabilities using broadcasting\n",
    "    # This replaces the nested loops with vectorized operations\n",
    "        # Compute the full tensor of log probabilities for this word position\n",
    "\n",
    "    print(f\"{log_forward=}\")\n",
    "    print(f\"{log_forward.shape=}\")\n",
    "\n",
    "    print(f\"{log_backward=}\")\n",
    "    print(f\"{log_backward.shape=}\")\n",
    "\n",
    "    print(f\"{transition=}\")\n",
    "    print(f\"{transition.shape=}\")\n",
    "\n",
    "    print(f\"{log_emission_sentence=}\")\n",
    "    print(f\"{log_emission_sentence.shape=}\")\n",
    "\n",
    "    print(f\"{log_forward_val=}\")\n",
    "    return (\n",
    "        log_forward[:, :-1, np.newaxis] +  # first tag dimension\n",
    "        log_backward[:, 1:].T[np.newaxis, :] +  # second tag dimension\n",
    "        transition[:, np.newaxis, :] +  # transition probabilities\n",
    "        log_emission_sentence[:, 1:].T[np.newaxis, :] -  # emission for next word\n",
    "        log_forward_val\n",
    "    )\n",
    "    \n",
    "    return si_probabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: ['Noun', 'Verb', 'Adjective']\n",
      "Word Indices: [1, 3, 2, 0]\n",
      "Word Sequence: ['the', 'quick', 'brown', 'fox']\n",
      "Forward Matrix:\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "Backward Matrix:\n",
      " [[120 110 100  90]\n",
      " [ 80  70  60  50]\n",
      " [ 40  30  20  10]]\n",
      "Forward Value: 10\n",
      "Transition Matrix:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Emission Matrix:\n",
      " [[ 11  22  33  44]\n",
      " [ 88  77  66  55]\n",
      " [ 99 111 222 333]]\n",
      "SI Probabilities from log_si_probs:\n",
      " [[[146. 118. 357.]\n",
      "  [126. 120. 237.]\n",
      "  [ 95. 133. 105.]]\n",
      "\n",
      " [[153. 125. 364.]\n",
      "  [133. 127. 244.]\n",
      "  [102. 140. 112.]]\n",
      "\n",
      " [[160. 132. 371.]\n",
      "  [140. 134. 251.]\n",
      "  [109. 147. 119.]]]\n",
      "SI Probabilities from log_si_probs_vec:\n",
      " [[[146 118 357]\n",
      "  [126 120 237]\n",
      "  [ 95 133 105]]\n",
      "\n",
      " [[153 125 364]\n",
      "  [133 127 244]\n",
      "  [102 140 112]]\n",
      "\n",
      " [[160 132 371]\n",
      "  [140 134 251]\n",
      "  [109 147 119]]]\n",
      "Are the outputs equivalent? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the parameters\n",
    "tags = ['Noun', 'Verb', 'Adjective']\n",
    "word_sequence = ['the', 'quick', 'brown', 'fox']\n",
    "word_indices = [1, 3, 2, 0]  # corresponding indices in a hypothetical vocabulary\n",
    "log_forward = np.array([\n",
    "    [1, 2, 3, 4],  # Values for Noun\n",
    "    [5, 6, 7, 8],  # Values for Verb\n",
    "    [9, 10, 11, 12]  # Values for Adjective\n",
    "])\n",
    "log_backward = np.array([\n",
    "    [120, 110, 100, 90],  # Values for Noun\n",
    "    [80, 70, 60, 50],  # Values for Verb\n",
    "    [40, 30, 20, 10]  # Values for Adjective\n",
    "])\n",
    "log_forward_val = 10\n",
    "\n",
    "# Define transition matrix with distinct values\n",
    "transition = np.array([\n",
    "    [1, 2, 3],  # From Noun to Noun, Verb, Adjective\n",
    "    [4, 5, 6],  # From Verb to Noun, Verb, Adjective\n",
    "    [7, 8, 9]   # From Adjective to Noun, Verb, Adjective\n",
    "])\n",
    "# Define emission matrix with distinct values\n",
    "vocab_size = max(word_indices) + 1\n",
    "emission = np.array([\n",
    "    [11, 22, 33, 44],  # Emissions for Noun\n",
    "    [88, 77, 66, 55],  # Emissions for Verb\n",
    "    [99, 111, 222, 333]   # Emissions for Adjective\n",
    "])\n",
    "\n",
    "# Print input values\n",
    "print(\"Tags:\", tags)\n",
    "print(\"Word Indices:\", word_indices)\n",
    "print(\"Word Sequence:\", word_sequence)\n",
    "print(\"Forward Matrix:\\n\", log_forward)\n",
    "print(\"Backward Matrix:\\n\", log_backward)\n",
    "print(\"Forward Value:\", log_forward_val)\n",
    "print(\"Transition Matrix:\\n\", transition)\n",
    "print(\"Emission Matrix:\\n\", emission)\n",
    "\n",
    "# Use the original function\n",
    "SI_probabilities = log_si_probs(tags, word_indices, log_forward, log_backward, log_forward_val, transition, emission)\n",
    "print(\"SI Probabilities from log_si_probs:\\n\", SI_probabilities)\n",
    "\n",
    "# Use the vectorized function\n",
    "SI_probabilities_vec = log_si_probs_vec(tags, word_indices, log_forward, log_backward, log_forward_val, transition, emission)\n",
    "print(\"SI Probabilities from log_si_probs_vec:\\n\", SI_probabilities_vec)\n",
    "\n",
    "# Check if the outputs are equivalent\n",
    "print(\"Are the outputs equivalent?\", np.allclose(SI_probabilities, SI_probabilities_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_forward shape: (3, 16)\n",
      "log_backward shape: (3, 16)\n",
      "log_transition shape: (3, 3)\n",
      "log_emission shape: (3, 16)\n",
      "log_forward_expanded shape: (3, 15, 1)\n",
      "log_backward_expanded shape: (1, 15, 3)\n",
      "log_transition_expanded shape: (3, 1, 3)\n",
      "log_emission_expanded shape: (1, 15, 3)\n",
      "si_probs shape: (3, 15, 3)\n",
      "[[[0.66114421 1.22219175 2.22468667]\n",
      "  [2.08331742 2.1094548  1.52780613]\n",
      "  [1.29384782 2.49302671 2.22043913]\n",
      "  [2.32852928 2.26259848 2.07784851]\n",
      "  [1.53940877 0.89471254 0.54066099]\n",
      "  [0.98628689 1.5304961  1.51890593]\n",
      "  [1.54700947 0.79884621 1.30599582]\n",
      "  [2.20457659 1.76904227 1.88809076]\n",
      "  [2.06422403 1.63954274 1.71387017]\n",
      "  [2.0287846  1.66068971 2.4593483 ]\n",
      "  [2.29036038 1.47356807 1.57253262]\n",
      "  [1.97639134 2.04910547 2.66755613]\n",
      "  [1.69628967 2.38655442 2.932019  ]\n",
      "  [1.74266376 2.89546503 2.8749465 ]\n",
      "  [1.27737396 1.81551306 1.78008485]]\n",
      "\n",
      " [[0.37570308 0.92981094 1.87278586]\n",
      "  [1.87487211 1.89406982 1.25290114]\n",
      "  [1.37188807 2.56412729 2.2320197 ]\n",
      "  [1.6792594  1.60638893 1.36211895]\n",
      "  [1.58809794 0.93646204 0.52289048]\n",
      "  [0.78882537 1.32609491 1.25498473]\n",
      "  [1.66225953 0.9071566  1.3547862 ]\n",
      "  [1.74037252 1.29789852 1.357427  ]\n",
      "  [1.72387462 1.29225366 1.30706107]\n",
      "  [1.75197899 1.37694442 2.11608301]\n",
      "  [2.10694562 1.28321364 1.32265819]\n",
      "  [1.73069429 1.79646875 2.3553994 ]\n",
      "  [1.26310986 1.94643494 2.43237952]\n",
      "  [1.59720989 2.74307149 2.66303295]\n",
      "  [1.34394012 1.87513955 1.78019133]]\n",
      "\n",
      " [[0.0519552  1.28192543 2.09681848]\n",
      "  [1.4522393  2.14729938 1.37804883]\n",
      "  [0.88887252 2.75697409 2.29678464]\n",
      "  [1.12474947 1.72774136 1.35538952]\n",
      "  [1.22632724 1.2505537  0.70890027]\n",
      "  [0.31461172 1.52774362 1.32855158]\n",
      "  [1.52964588 1.45040532 1.76995305]\n",
      "  [1.87730854 2.1106969  2.04214352]\n",
      "  [1.37841387 1.62265527 1.50938082]\n",
      "  [1.32050125 1.62132905 2.23238577]\n",
      "  [2.4366765  2.28880689 2.20016956]\n",
      "  [0.7015775  1.44321432 1.8740631 ]\n",
      "  [1.161222   2.52040944 2.87827215]\n",
      "  [0.92197905 2.74370302 2.53558261]\n",
      "  [0.8241887  2.03125049 1.8082204 ]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "num_tags = 3\n",
    "num_words = 16\n",
    "word_indices = np.array([i for i in range(16)])  # Example word indices\n",
    "log_forward = np.random.rand(num_tags, num_words)  # Shape: (num_tags, num_words)\n",
    "log_backward = np.random.rand(num_tags, num_words)  # Shape: (num_tags, num_words)\n",
    "log_transition = np.random.rand(num_tags, num_tags)  # Shape: (num_tags, num_tags)\n",
    "log_emission = np.random.rand(num_tags, num_words)  # Shape: (num_tags, num_words)\n",
    "log_forward_val = np.random.rand()  # Scalar for simplicity\n",
    "\n",
    "# Prepare for vectorized computation\n",
    "next_word_indices = word_indices[1:]  # Shape: (num_words - 1,)\n",
    "\n",
    "log_emission_sentence = log_emission[:, word_indices]\n",
    "\n",
    "# Expand dimensions to align shapes for broadcasting\n",
    "log_forward_expanded = log_forward[:, :-1, np.newaxis]\n",
    "log_backward_expanded = log_backward[:, 1:].T[np.newaxis, :]\n",
    "log_transition_expanded = log_transition[:, np.newaxis, :]\n",
    "log_emission_expanded = log_emission_sentence[:, 1:].T[np.newaxis, :]\n",
    "\n",
    "# Print results to verify shapes\n",
    "print(\"log_forward shape:\", log_forward.shape)\n",
    "print(\"log_backward shape:\", log_backward.shape)\n",
    "print(\"log_transition shape:\", log_transition.shape)\n",
    "print(\"log_emission shape:\", log_emission.shape)\n",
    "print(\"log_forward_expanded shape:\", log_forward_expanded.shape)\n",
    "print(\"log_backward_expanded shape:\", log_backward_expanded.shape)\n",
    "print(\"log_transition_expanded shape:\", log_transition_expanded.shape)\n",
    "print(\"log_emission_expanded shape:\", log_emission_expanded.shape)\n",
    "\n",
    "# Fully vectorized computation\n",
    "si_probs = (\n",
    "    log_forward_expanded +\n",
    "    log_backward_expanded +\n",
    "    log_transition_expanded +\n",
    "    log_emission_expanded -\n",
    "    log_forward_val\n",
    ")  # Final shape: (num_tags, num_words-1, num_tags)\n",
    "print(\"si_probs shape:\", si_probs.shape)\n",
    "\n",
    "\n",
    "print(si_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "import scipy.sparse as sc\n",
    "\n",
    "def compute_a_loop(num_tags, word_indices, log_si_probabilities):\n",
    "    log_si_probabilities = np.exp(log_si_probabilities)\n",
    "    a = np.zeros((num_tags, num_tags))\n",
    "    for j in range(num_tags):\n",
    "        for i in range(num_tags):\n",
    "            for t in range(len(word_indices)-1):\n",
    "                a[j,i] = a[j,i] + log_si_probabilities[j,t,i]\n",
    "\n",
    "            denomenator_a = [log_si_probabilities[j, t_x, i_x] for t_x in range(len(word_indices) - 1) for i_x in range(num_tags)]\n",
    "            denomenator_a = sum(denomenator_a)\n",
    "\n",
    "            if (denomenator_a == 0):\n",
    "                a[j,i] = 0\n",
    "            else:\n",
    "                a[j,i] = a[j,i]/denomenator_a\n",
    "    return np.log(a)\n",
    "\n",
    "def compute_a_vectorized(num_tags, word_indices, log_si_probabilities):\n",
    "\n",
    "    # # Summing over time steps for each transition pair (j, i)\n",
    "    # a_log = logsumexp(log_si_probabilities, axis=1)  # Shape: (num_tags, num_tags)\n",
    "\n",
    "    # # Normalizing across each row\n",
    "    # denom_a_log = logsumexp(log_si_probabilities, axis=(1, 2))[:, np.newaxis]  # Shape: (num_tags, 1)\n",
    "    # # print(log_si_probabilities.shape)\n",
    "    # # print(a_log.shape)\n",
    "    # # print(denom_a_log.shape)\n",
    "    # a_log_normalized = a_log - denom_a_log  # Broadcasting to normalize each row\n",
    "    a_log_normalized = logsumexp(log_si_probabilities, axis=1) - logsumexp(log_si_probabilities, axis=(1, 2))[:, np.newaxis]\n",
    "\n",
    "    return a_log_normalized\n",
    "\n",
    "def compute_b_loop(num_tags, words_dict, word_indices, log_gamma_probabilities):\n",
    "    b_log = np.full((num_tags, len(words_dict)), -np.inf)\n",
    "\n",
    "    for j in range(num_tags):  # Loop over states\n",
    "        for i in range(len(words_dict)):  # Loop over observation symbols\n",
    "            # Find indices where the observation matches the current symbol\n",
    "            indices = [idx for idx, val in enumerate(word_indices) if val == words_dict[i]]\n",
    "            \n",
    "            if indices:  # Only process if there are matching indices\n",
    "                numerator_logs = log_gamma_probabilities[j, indices]\n",
    "                # print(f\"{j=}, {i=}, {indices=}, {numerator_logs=}\")\n",
    "                numerator_b_log = logsumexp(numerator_logs)\n",
    "            else:\n",
    "                numerator_b_log = -np.inf\n",
    "            denomenator_logs = log_gamma_probabilities[j, :]\n",
    "            denomenator_b_log = logsumexp(denomenator_logs)\n",
    "            # print(f\"{j=}, {i=}, {numerator_b_log=}, {denomenator_b_log=}\")\n",
    "\n",
    "\n",
    "            # Avoid log(0) issues by checking the denominator\n",
    "            if np.isneginf(denomenator_b_log):\n",
    "                b_log[j, i] = -np.inf  # Probability is 0\n",
    "            else:\n",
    "                b_log[j, i] = numerator_b_log - denomenator_b_log\n",
    "    return b_log\n",
    "\n",
    "def compute_b_vectorized(num_tags, num_words, word_indices, log_gamma_probabilities):\n",
    "    # Assume `word_indices`, `log_gamma_probabilities`, and `states` are already defined\n",
    "\n",
    "    b_denominator_logs = logsumexp(log_gamma_probabilities, axis=1, keepdims=True)  # Shape: (num_states, 1)\n",
    "    # Pray we don't need to handle cases where denominator is -inf\n",
    "    assert np.all(~np.isneginf(b_denominator_logs)), \"Error: denominator contains -inf values.\"\n",
    "    unique_word_indices, inverse_indices = np.unique(word_indices, return_inverse=True)\n",
    "\n",
    "    # sparse_mask = sc.coo_matrix(\n",
    "    # (np.ones_like(inverse_indices), (inverse_indices, np.arange(len(inverse_indices)))),\n",
    "    # shape=(len(unique_word_indices), len(inverse_indices))\n",
    "    # )\n",
    "\n",
    "    # # Compute the log-sum-exp in a vectorized way\n",
    "    # numerator_logs = np.full((log_gamma_probabilities.shape[0], len(unique_word_indices)), -np.inf)  # Initialize with log(0)\n",
    "    # for state in range(log_gamma_probabilities.shape[0]):  # Iterate over states\n",
    "    #     # Multiply sparse mask with the log_gamma_probabilities for this state\n",
    "    #     numerator_logs[state, :] = logsumexp(\n",
    "    #         log_gamma_probabilities[state, :] + sparse_mask.toarray(), axis=1\n",
    "    #     )\n",
    "\n",
    "    num_unique_words = len(unique_word_indices)\n",
    "    b_numerator_logs = np.full((num_tags, num_unique_words), -np.inf)\n",
    "    # np.add.at(numerator_logs, (slice(None), inverse_indices), log_gamma_probabilities)\n",
    "    for idx in range(num_unique_words):\n",
    "        mask = (inverse_indices == idx)\n",
    "        b_numerator_logs[:, idx] = logsumexp(log_gamma_probabilities[:, mask], axis=1)\n",
    "\n",
    "    log_b = np.full((num_tags, num_words), -np.inf)\n",
    "    log_b[:, unique_word_indices] = b_numerator_logs - b_denominator_logs\n",
    "    \n",
    "    return log_b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_a_loop:\n",
      " [[-1.10219086 -3.66166884 -1.61652908 -3.74922431 -1.3043017  -2.08406434\n",
      "  -3.7189444 ]\n",
      " [-2.64303872 -2.19181939 -1.60251642 -4.43653522 -6.6008387  -0.57463624\n",
      "  -3.22773675]\n",
      " [-1.85253657 -1.36519206 -3.03809853 -2.65899614 -0.86333553 -3.06796228\n",
      "  -6.42760087]\n",
      " [-1.44441396 -1.86768374 -1.25691842 -6.71845405 -1.93542335 -5.42602742\n",
      "  -1.74220905]\n",
      " [-5.21784892 -1.24818718 -2.27448585 -2.24581097 -3.56983191 -2.91484588\n",
      "  -0.87588812]\n",
      " [-4.12268407 -3.49049773 -0.5819955  -1.35982249 -6.93000815 -3.80409604\n",
      "  -2.16659137]\n",
      " [-3.19633269 -2.93555601 -5.09372299 -0.43832788 -1.76650251 -3.00104091\n",
      "  -3.37926641]]\n",
      "log_a_vectorized:\n",
      " [[-1.10219086 -3.66166884 -1.61652908 -3.74922431 -1.3043017  -2.08406434\n",
      "  -3.7189444 ]\n",
      " [-2.64303872 -2.19181939 -1.60251642 -4.43653522 -6.6008387  -0.57463624\n",
      "  -3.22773675]\n",
      " [-1.85253657 -1.36519206 -3.03809853 -2.65899614 -0.86333553 -3.06796228\n",
      "  -6.42760087]\n",
      " [-1.44441396 -1.86768374 -1.25691842 -6.71845405 -1.93542335 -5.42602742\n",
      "  -1.74220905]\n",
      " [-5.21784892 -1.24818718 -2.27448585 -2.24581097 -3.56983191 -2.91484588\n",
      "  -0.87588812]\n",
      " [-4.12268407 -3.49049773 -0.5819955  -1.35982249 -6.93000815 -3.80409604\n",
      "  -2.16659137]\n",
      " [-3.19633269 -2.93555601 -5.09372299 -0.43832788 -1.76650251 -3.00104091\n",
      "  -3.37926641]]\n",
      "Are 'a' matrices equal? True\n",
      "\n",
      "log_b_loop:\n",
      " [[       -inf -0.7604811  -1.29457791 -1.35268546        -inf        -inf]\n",
      " [       -inf -4.11875658 -0.01688818 -7.63829244        -inf        -inf]\n",
      " [       -inf -1.90752069 -7.27560344 -0.16150791        -inf        -inf]\n",
      " [       -inf -2.88920494 -2.98306625 -0.11233785        -inf        -inf]\n",
      " [       -inf -0.57664189 -5.89199133 -0.83135968        -inf        -inf]\n",
      " [       -inf -1.59044382 -4.04756309 -0.25012943        -inf        -inf]\n",
      " [       -inf -0.27514608 -1.86622783 -2.45535537        -inf        -inf]]\n",
      "log_b_vectorized:\n",
      " [[       -inf -0.7604811  -1.29457791 -1.35268546        -inf        -inf]\n",
      " [       -inf -4.11875658 -0.01688818 -7.63829244        -inf        -inf]\n",
      " [       -inf -1.90752069 -7.27560344 -0.16150791        -inf        -inf]\n",
      " [       -inf -2.88920494 -2.98306625 -0.11233785        -inf        -inf]\n",
      " [       -inf -0.57664189 -5.89199133 -0.83135968        -inf        -inf]\n",
      " [       -inf -1.59044382 -4.04756309 -0.25012943        -inf        -inf]\n",
      " [       -inf -0.27514608 -1.86622783 -2.45535537        -inf        -inf]]\n",
      "Are 'b' matrices equal? True\n"
     ]
    }
   ],
   "source": [
    "# Dummy variables\n",
    "num_tags = 7\n",
    "word_indices = [1, 2, 3, 1]\n",
    "words_dict = {0: 0, 1: 1, 2: 2, 3:3, 4:4, 5:5}\n",
    "log_si_probabilities = np.random.uniform(-10, 0, (num_tags, len(word_indices) - 1, num_tags))\n",
    "log_gamma_probabilities = np.random.uniform(-10, 0, (num_tags, len(word_indices)))\n",
    "\n",
    "# Compute \"a\" matrices\n",
    "log_a_loop = compute_a_loop(num_tags, word_indices, log_si_probabilities)\n",
    "log_a_vectorized = compute_a_vectorized(num_tags, word_indices, log_si_probabilities)\n",
    "\n",
    "# Compute \"b\" matrices\n",
    "log_b_loop = compute_b_loop(num_tags, words_dict, word_indices, log_gamma_probabilities)\n",
    "log_b_vectorized = compute_b_vectorized(num_tags, len(words_dict), word_indices, log_gamma_probabilities)\n",
    "\n",
    "# Print and verify outputs\n",
    "print(\"log_a_loop:\\n\", log_a_loop)\n",
    "print(\"log_a_vectorized:\\n\", log_a_vectorized)\n",
    "print(\"Are 'a' matrices equal?\", np.allclose(log_a_loop, log_a_vectorized, atol=1e-6))\n",
    "\n",
    "print(\"\\nlog_b_loop:\\n\", log_b_loop)\n",
    "print(\"log_b_vectorized:\\n\", log_b_vectorized)\n",
    "print(\"Are 'b' matrices equal?\", np.allclose(log_b_loop, log_b_vectorized, atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration No:  1\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.7859 0.2141]\n",
      " [0.2094 0.7906]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.2005 0.1735 0.626 ]\n",
      " [0.5016 0.284  0.2145]]\n",
      "New forward probability:  5.695152119409513e-06\n",
      "Difference in forward probability:  5.002073262273513e-06\n",
      "\n",
      "Iteration No:  2\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.7185 0.2815]\n",
      " [0.2161 0.7839]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.235  0.1419 0.6231]\n",
      " [0.4256 0.2976 0.2768]]\n",
      "New forward probability:  7.128566815415427e-06\n",
      "Difference in forward probability:  1.4334146960059136e-06\n",
      "\n",
      "Iteration No:  3\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.6595 0.3405]\n",
      " [0.2027 0.7973]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.2536 0.1131 0.6333]\n",
      " [0.3925 0.3032 0.3043]]\n",
      "New forward probability:  7.898268000620344e-06\n",
      "Difference in forward probability:  7.697011852049176e-07\n",
      "\n",
      "Iteration No:  4\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.6083 0.3917]\n",
      " [0.1856 0.8144]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.2609 0.0838 0.6553]\n",
      " [0.378  0.3076 0.3144]]\n",
      "New forward probability:  8.505915984403414e-06\n",
      "Difference in forward probability:  6.076479837830701e-07\n",
      "\n",
      "Iteration No:  5\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.5653 0.4347]\n",
      " [0.1681 0.8319]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.2583 0.0561 0.6856]\n",
      " [0.373  0.3102 0.3168]]\n",
      "New forward probability:  9.071219292698616e-06\n",
      "Difference in forward probability:  5.653033082952012e-07\n",
      "\n",
      "Iteration No:  6\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.5308 0.4692]\n",
      " [0.151  0.849 ]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.2474 0.0334 0.7192]\n",
      " [0.3734 0.3102 0.3163]]\n",
      "New forward probability:  9.58895507871377e-06\n",
      "Difference in forward probability:  5.177357860151544e-07\n",
      "\n",
      "Iteration No:  7\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.5034 0.4966]\n",
      " [0.1346 0.8654]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.2298 0.0179 0.7523]\n",
      " [0.3766 0.3076 0.3159]]\n",
      "New forward probability:  1.0039926616360996e-05\n",
      "Difference in forward probability:  4.5097153764722633e-07\n",
      "\n",
      "Iteration No:  8\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.4797 0.5203]\n",
      " [0.1191 0.8809]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.2075 0.0087 0.7838]\n",
      " [0.3808 0.3027 0.3165]]\n",
      "New forward probability:  1.0433458051993812e-05\n",
      "Difference in forward probability:  3.935314356328161e-07\n",
      "\n",
      "Iteration No:  9\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.4567 0.5433]\n",
      " [0.1045 0.8955]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.182  0.0039 0.8141]\n",
      " [0.3849 0.2967 0.3184]]\n",
      "New forward probability:  1.0800056451977317e-05\n",
      "Difference in forward probability:  3.66598399983505e-07\n",
      "\n",
      "Iteration No:  10\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.4328 0.5672]\n",
      " [0.0905 0.9095]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.1541 0.0016 0.8443]\n",
      " [0.3885 0.2901 0.3214]]\n",
      "New forward probability:  1.1170888116497158e-05\n",
      "Difference in forward probability:  3.7083166451984063e-07\n",
      "\n",
      "Iteration No:  11\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.4079 0.5921]\n",
      " [0.0773 0.9227]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[1.247e-01 6.000e-04 8.747e-01]\n",
      " [3.912e-01 2.837e-01 3.252e-01]]\n",
      "New forward probability:  1.1564990702790385e-05\n",
      "Difference in forward probability:  3.9410258629322674e-07\n",
      "\n",
      "Iteration No:  12\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.3829 0.6171]\n",
      " [0.0649 0.9351]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[9.500e-02 2.000e-04 9.048e-01]\n",
      " [3.929e-01 2.777e-01 3.294e-01]]\n",
      "New forward probability:  1.1984206072418657e-05\n",
      "Difference in forward probability:  4.1921536962827176e-07\n",
      "\n",
      "Iteration No:  13\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.3597 0.6403]\n",
      " [0.0534 0.9466]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[6.700e-02 1.000e-04 9.330e-01]\n",
      " [3.936e-01 2.725e-01 3.339e-01]]\n",
      "New forward probability:  1.2412164222668813e-05\n",
      "Difference in forward probability:  4.2795815025015677e-07\n",
      "\n",
      "Iteration No:  14\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.3403 0.6597]\n",
      " [0.0431 0.9569]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.0429 0.     0.9571]\n",
      " [0.3934 0.2682 0.3384]]\n",
      "New forward probability:  1.281889755637925e-05\n",
      "Difference in forward probability:  4.0673333371043656e-07\n",
      "\n",
      "Iteration No:  15\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.326  0.674 ]\n",
      " [0.0342 0.9658]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.0246 0.     0.9754]\n",
      " [0.3924 0.2647 0.3429]]\n",
      "New forward probability:  1.3173129020569065e-05\n",
      "Difference in forward probability:  3.5423146418981556e-07\n",
      "\n",
      "Iteration No:  16\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.317  0.683 ]\n",
      " [0.0266 0.9734]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.0126 0.     0.9874]\n",
      " [0.3908 0.2621 0.3471]]\n",
      "New forward probability:  1.3456378721132235e-05\n",
      "Difference in forward probability:  2.8324970056316973e-07\n",
      "\n",
      "Iteration No:  17\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.3125 0.6875]\n",
      " [0.0204 0.9796]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.0058 0.     0.9942]\n",
      " [0.3891 0.2601 0.3508]]\n",
      "New forward probability:  1.366841466404495e-05\n",
      "Difference in forward probability:  2.120359429127144e-07\n",
      "\n",
      "Iteration No:  18\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.3109 0.6891]\n",
      " [0.0155 0.9845]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[0.0024 0.     0.9976]\n",
      " [0.3875 0.2586 0.3539]]\n",
      "New forward probability:  1.3821595637742053e-05\n",
      "Difference in forward probability:  1.5318097369710302e-07\n",
      "\n",
      "Iteration No:  19\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.311  0.689 ]\n",
      " [0.0117 0.9883]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[9.000e-04 0.000e+00 9.991e-01]\n",
      " [3.861e-01 2.575e-01 3.563e-01]]\n",
      "New forward probability:  1.3931545687632912e-05\n",
      "Difference in forward probability:  1.0995004989085946e-07\n",
      "\n",
      "Iteration No:  20\n",
      "\n",
      "Matrix a:\n",
      "\n",
      "[[0.312  0.688 ]\n",
      " [0.0088 0.9912]]\n",
      "\n",
      "Matrix b:\n",
      "\n",
      "[[3.000e-04 0.000e+00 9.997e-01]\n",
      " [3.850e-01 2.567e-01 3.582e-01]]\n",
      "New forward probability:  1.40112936024903e-05\n",
      "Difference in forward probability:  7.974791485738815e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "#generating initial probabilities\n",
    "\n",
    "#transition probabilities\n",
    "transition = np.array([[0.8,0.1],\n",
    "                       [0.1,0.8]])\n",
    "#Emission probabilities\n",
    "emission = np.array([[0.1,0.2,0.7],\n",
    "                     [0.7,0.2,0.1]])\n",
    "\n",
    "#defining states and sequence symbols\n",
    "states = ['H','C']\n",
    "states_dic = {'H':0, 'C':1}\n",
    "sequence_syms = {'1':0,'2':1,'3':2}\n",
    "sequence = ['1','2','3']\n",
    "\n",
    "#test sequence\n",
    "test_sequence = '331122313'\n",
    "test_sequence = [x for x in test_sequence]\n",
    "\n",
    "#probabilities of going to end state\n",
    "end_probs = [0.1, 0.1]\n",
    "#probabilities of going from start state\n",
    "start_probs = [0.5, 0.5]\n",
    "\n",
    "\n",
    "#function to find forward probabilities\n",
    "def forward_probs():\n",
    "    # node values stored during forward algorithm\n",
    "    node_values_fwd = np.zeros((len(states), len(test_sequence)))\n",
    "\n",
    "    for i, sequence_val in enumerate(test_sequence):\n",
    "        for j in range(len(states)):\n",
    "            # if first sequence value then do this\n",
    "            if (i == 0):\n",
    "                node_values_fwd[j, i] = start_probs[j] * emission[j, sequence_syms[sequence_val]]\n",
    "            # else perform this\n",
    "            else:\n",
    "                values = [node_values_fwd[k, i - 1] * emission[j, sequence_syms[sequence_val]] * transition[k, j] for k in\n",
    "                          range(len(states))]\n",
    "                node_values_fwd[j, i] = sum(values)\n",
    "\n",
    "    #end state value\n",
    "    end_state = np.multiply(node_values_fwd[:, -1], end_probs)\n",
    "    end_state_val = sum(end_state)\n",
    "    return node_values_fwd, end_state_val\n",
    "\n",
    "\n",
    "\n",
    "#function to find backward probabilities\n",
    "def backward_probs():\n",
    "    # node values stored during forward algorithm\n",
    "    node_values_bwd = np.zeros((len(states), len(test_sequence)))\n",
    "\n",
    "    #for i, sequence_val in enumerate(test_sequence):\n",
    "    for i in range(1,len(test_sequence)+1):\n",
    "        for j in range(len(states)):\n",
    "            # if first sequence value then do this\n",
    "            if (-i == -1):\n",
    "                node_values_bwd[j, -i] = end_probs[j]\n",
    "            # else perform this\n",
    "            else:\n",
    "                values = [node_values_bwd[k, -i+1] * emission[k, sequence_syms[test_sequence[-i+1]]] * transition[j, k] for k in range(len(states))]\n",
    "                node_values_bwd[j, -i] = sum(values)\n",
    "\n",
    "    #start state value\n",
    "    start_state = [node_values_bwd[m,0] * emission[m, sequence_syms[test_sequence[0]]] for m in range(len(states))]\n",
    "    start_state = np.multiply(start_state, start_probs)\n",
    "    start_state_val = sum(start_state)\n",
    "    return node_values_bwd, start_state_val\n",
    "\n",
    "\n",
    "#function to find si probabilities\n",
    "def si_probs(forward, backward, forward_val):\n",
    "\n",
    "    si_probabilities = np.zeros((len(states), len(test_sequence)-1, len(states)))\n",
    "\n",
    "    for i in range(len(test_sequence)-1):\n",
    "        for j in range(len(states)):\n",
    "            for k in range(len(states)):\n",
    "                si_probabilities[j,i,k] = ( forward[j,i] * backward[k,i+1] * transition[j,k] * emission[k,sequence_syms[test_sequence[i+1]]] ) \\\n",
    "                                                    / forward_val\n",
    "    return si_probabilities\n",
    "\n",
    "#function to find gamma probabilities\n",
    "def gamma_probs(forward, backward, forward_val):\n",
    "\n",
    "    gamma_probabilities = np.zeros((len(states), len(test_sequence)))\n",
    "\n",
    "    for i in range(len(test_sequence)):\n",
    "        for j in range(len(states)):\n",
    "            #gamma_probabilities[j,i] = ( forward[j,i] * backward[j,i] * emission[j,sequence_syms[test_sequence[i]]] ) / forward_val\n",
    "            gamma_probabilities[j, i] = (forward[j, i] * backward[j, i]) / forward_val\n",
    "\n",
    "    return gamma_probabilities\n",
    "\n",
    "\n",
    "\n",
    "#performing iterations until convergence\n",
    "\n",
    "for iteration in range(2000):\n",
    "\n",
    "    print('\\nIteration No: ', iteration + 1)\n",
    "    # print('\\nTransition:\\n ', transition)\n",
    "    # print('\\nEmission: \\n', emission)\n",
    "\n",
    "    #Calling probability functions to calculate all probabilities\n",
    "    fwd_probs, fwd_val = forward_probs()\n",
    "    bwd_probs, bwd_val = backward_probs()\n",
    "    si_probabilities = si_probs(fwd_probs, bwd_probs, fwd_val)\n",
    "    gamma_probabilities = gamma_probs(fwd_probs, bwd_probs, fwd_val)\n",
    "\n",
    "    # print('Forward Probs:')\n",
    "    # print(np.matrix(fwd_probs))\n",
    "    #\n",
    "    # print('Backward Probs:')\n",
    "    # print(np.matrix(bwd_probs))\n",
    "    #\n",
    "    # print('Si Probs:')\n",
    "    # print(si_probabilities)\n",
    "    #\n",
    "    # print('Gamma Probs:')\n",
    "    # print(np.matrix(gamma_probabilities))\n",
    "\n",
    "    #caclculating 'a' and 'b' matrices\n",
    "    a = np.zeros((len(states), len(states)))\n",
    "    b = np.zeros((len(states), len(sequence_syms)))\n",
    "\n",
    "    #'a' matrix\n",
    "    for j in range(len(states)):\n",
    "        for i in range(len(states)):\n",
    "            for t in range(len(test_sequence)-1):\n",
    "                a[j,i] = a[j,i] + si_probabilities[j,t,i]\n",
    "\n",
    "            denomenator_a = [si_probabilities[j, t_x, i_x] for t_x in range(len(test_sequence) - 1) for i_x in range(len(states))]\n",
    "            denomenator_a = sum(denomenator_a)\n",
    "\n",
    "            if (denomenator_a == 0):\n",
    "                a[j,i] = 0\n",
    "            else:\n",
    "                a[j,i] = a[j,i]/denomenator_a\n",
    "\n",
    "    #'b' matrix\n",
    "    for j in range(len(states)): #states\n",
    "        for i in range(len(sequence)): #seq\n",
    "            indices = [idx for idx, val in enumerate(test_sequence) if val == sequence[i]]\n",
    "            numerator_b = sum( gamma_probabilities[j,indices] )\n",
    "            denomenator_b = sum( gamma_probabilities[j,:] )\n",
    "\n",
    "            if (denomenator_b == 0):\n",
    "                b[j,i] = 0\n",
    "            else:\n",
    "                b[j, i] = numerator_b / denomenator_b\n",
    "\n",
    "\n",
    "    print('\\nMatrix a:\\n')\n",
    "    print(np.matrix(a.round(decimals=4)))\n",
    "    print('\\nMatrix b:\\n')\n",
    "    print(np.matrix(b.round(decimals=4)))\n",
    "\n",
    "    transition = a\n",
    "    emission = b\n",
    "\n",
    "    new_fwd_temp, new_fwd_temp_val = forward_probs()\n",
    "    print('New forward probability: ', new_fwd_temp_val)\n",
    "    diff =  np.abs(fwd_val - new_fwd_temp_val)\n",
    "    print('Difference in forward probability: ', diff)\n",
    "\n",
    "    if (diff < 0.0000001):\n",
    "        break\n",
    "\n",
    "\n",
    "c = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.17118298 -0.87134821 -0.9182008  -1.00348155]\n",
      "backward_vals=array([[-0.79492987, -0.38136756, -0.5389965 , -1.09861229],\n",
      "       [-0.94908055, -2.61495978, -1.38629436, -1.09861229],\n",
      "       [-1.82454929, -1.41098697, -1.79175947, -1.09861229]])\n",
      "Forward: [[-1.13140211 -2.79836133 -0.97948475 -0.82782974]\n",
      " [-1.64222774 -0.13960775 -3.22820836 -0.85115559]\n",
      " [-0.725937   -2.66799951 -0.53637075 -1.99449731]]\n",
      "Backward: [[-0.79492987 -0.38136756 -0.5389965  -1.09861229]\n",
      " [-0.94908055 -2.61495978 -1.38629436 -1.09861229]\n",
      " [-1.82454929 -1.41098697 -1.79175947 -1.09861229]]\n",
      "0.40160745935373554\n"
     ]
    }
   ],
   "source": [
    "def forward_log_vec(num_tags, num_words, log_initial, log_transition, log_emission_sentence):\n",
    "    log_probs = np.full((num_tags, num_words), -np.inf)\n",
    "    scaling_factors = np.zeros(num_words)\n",
    "    \n",
    "    # Initial step with normalization\n",
    "    log_probs[:, 0] = log_initial + log_emission_sentence[:, 0]\n",
    "    factor0 = logsumexp(log_probs[:, 0])\n",
    "    log_probs[:, 0] -= factor0\n",
    "    scaling_factors[0] = factor0\n",
    "    \n",
    "    for t in range(1, num_words):\n",
    "        # Compute log probabilities\n",
    "        log_probs[:, t] = logsumexp(log_probs[:, t-1][:, np.newaxis] + log_transition, axis=0) + log_emission_sentence[:, t]\n",
    "        \n",
    "        # Normalize at each time step\n",
    "        factor = logsumexp(log_probs[:, t])\n",
    "        log_probs[:, t] -= factor\n",
    "        scaling_factors[t] = factor\n",
    "    print(scaling_factors)\n",
    "    \n",
    "    return log_probs, logsumexp(scaling_factors)\n",
    "\n",
    "def backward_log_vec(num_tags, num_words, log_transition, log_emission_sentence):\n",
    "    # num_words = len(word_indices)\n",
    "    backward_vals = np.full((num_tags, num_words), -np.inf)\n",
    "    # Last column, deduct scaling factor\n",
    "    backward_vals[:, -1] = 0\n",
    "    backward_vals[:, -1] -= logsumexp(backward_vals[:, -1])\n",
    "    for t in range(num_words-2, -1, -1):\n",
    "        backward_vals[:, t] = logsumexp(backward_vals[:, t + 1][:, np.newaxis] + log_transition, axis=1) + log_emission_sentence[:, t + 1]\n",
    "        # NORMALISE\n",
    "        backward_vals[:, t] -= logsumexp(backward_vals[:, t])\n",
    "    print(f\"{backward_vals=}\")\n",
    "\n",
    "    return backward_vals\n",
    "\n",
    "num_tags = 3\n",
    "num_words = 4\n",
    "log_initial = np.log(np.array([0.2, 0.3, 0.5]))\n",
    "log_transition = np.log(np.array([[0.1, 0.6, 0.3],\n",
    "                                  [0.4, 0.1, 0.5],\n",
    "                                  [0.3, 0.5, 0.2]]))\n",
    "log_emission_sentence = np.log(np.array([[0.5, 0.1, 0.4, 0.7],\n",
    "                                         [0.2, 0.8, 0.1, 0.3],\n",
    "                                         [0.3, 0.1, 0.5, 0.2]]))\n",
    "\n",
    "# Call forward and backward functions\n",
    "log_probs_forward, forward_value = forward_log_vec(num_tags, num_words, log_initial, log_transition, log_emission_sentence)\n",
    "log_probs_backward = backward_log_vec(num_tags, num_words, log_transition, log_emission_sentence)\n",
    "\n",
    "# Assertion\n",
    "# assert np.isclose(forward_scale_sum, backward_scale_sum), \"The sums of scaling factors should be the same\"\n",
    "\n",
    "print(\"Forward:\", log_probs_forward)\n",
    "print(\"Backward:\", log_probs_backward)\n",
    "print(forward_value)\n",
    "# print(\"Assertion passed: Forward and backward scaling factors are equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Matrix:\n",
      " [[-0.79492987 -0.38136756 -0.5389965  -1.09861229]\n",
      " [-0.94908055 -2.61495978 -1.38629436 -1.09861229]\n",
      " [-1.82454929 -1.41098697 -1.79175947 -1.09861229]]\n",
      "Backward Matrix:\n",
      " [[-0.79492987 -0.38136756 -0.5389965  -1.09861229]\n",
      " [-0.94908055 -2.61495978 -1.38629436 -1.09861229]\n",
      " [-1.82454929 -1.41098697 -1.79175947 -1.09861229]]\n",
      "Forward Value: 0.40160745935373554\n",
      "Transition Matrix:\n",
      " [[-2.30258509 -0.51082562 -1.2039728 ]\n",
      " [-0.91629073 -2.30258509 -0.69314718]\n",
      " [-1.2039728  -0.69314718 -1.60943791]]\n",
      "Emission Matrix:\n",
      " [[-0.69314718 -2.30258509 -0.91629073 -0.35667494]\n",
      " [-1.60943791 -0.22314355 -2.30258509 -1.2039728 ]\n",
      " [-1.2039728  -2.30258509 -0.69314718 -1.60943791]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m word_indicess \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use the original function\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m SI_probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mlog_si_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_indicess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs_backward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_transition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_emission_sentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSI Probabilities from log_si_probs:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, SI_probabilities)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Use the vectorized function\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[117], line 9\u001b[0m, in \u001b[0;36mlog_si_probs\u001b[0;34m(num_tags, word_indices, log_forward, log_backward, log_forward_val, transition, log_emission_sentences)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tags):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tags):\n\u001b[0;32m----> 9\u001b[0m             \u001b[43msi_probabilities\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     10\u001b[0m                 log_forward[j, i] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     11\u001b[0m                 log_backward[k, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     12\u001b[0m                 transition[j, k] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     13\u001b[0m                 log_emission_sentences[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m     14\u001b[0m                 log_forward_val\n\u001b[1;32m     15\u001b[0m             )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m si_probabilities\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Print input values\n",
    "# print(\"Tags:\", tags)\n",
    "# print(\"Word Indices:\", word_indices)\n",
    "# print(\"Word Sequence:\", word_sequence)\n",
    "print(\"Forward Matrix:\\n\", log_probs_backward)\n",
    "print(\"Backward Matrix:\\n\", log_probs_backward)\n",
    "print(\"Forward Value:\", forward_value)\n",
    "print(\"Transition Matrix:\\n\", log_transition)\n",
    "print(\"Emission Matrix:\\n\", log_emission_sentence)\n",
    "\n",
    "word_indicess = [0, 1, 2, 3]\n",
    "\n",
    "# Use the original function\n",
    "SI_probabilities = log_si_probs(num_tags, word_indicess, log_probs_forward, log_probs_backward, forward_value, log_transition, log_emission_sentence)\n",
    "print(\"SI Probabilities from log_si_probs:\\n\", SI_probabilities)\n",
    "\n",
    "# Use the vectorized function\n",
    "SI_probabilities_vec = log_si_probs_vec(log_probs_forward, log_probs_backward, forward_value, log_transition, log_emission_sentence)\n",
    "print(\"SI Probabilities from log_si_probs_vec:\\n\", SI_probabilities_vec)\n",
    "\n",
    "# Check if the outputs are equivalent\n",
    "print(\"Are the outputs equivalent?\", np.allclose(SI_probabilities, SI_probabilities_vec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
